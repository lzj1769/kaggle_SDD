Training on 10055 images, class 1: 718, class 2: 198, class 3: 4120, class 4: 640
Validate on 2513 images, class 1: 179, class 2: 49, class 3: 1030, class 4: 161
Epoch: 1/100 |  time : 09/16/19-20:02:26
=================================================================
train_loss: 0.07696520, train_bce_loss: 0.02747566, train_dice_loss: 0.47697749, train_vae_loss: 0.07286929
valid_loss: 0.04961362, valid_bce_loss: 0.02469546, valid_dice_loss: 0.24534775, valid_vae_loss: 0.05322468
0.1 | 0.92212 | 0.97394 | 0.25974 | 0.71457 | 0.71759 | 0.92886 | 0.98052 | 0.46783 | 0.92141 | 0.82466
0.2 | 0.92500 | 0.97642 | 0.35081 | 0.86471 | 0.77924 | 0.92886 | 0.98052 | 0.56342 | 0.92403 | 0.84921
0.3 | 0.92610 | 0.97742 | 0.40933 | 0.89672 | 0.80239 | 0.92886 | 0.98052 | 0.62425 | 0.92558 | 0.86480
0.4 | 0.92719 | 0.97841 | 0.45265 | 0.90960 | 0.81696 | 0.92886 | 0.98052 | 0.65674 | 0.92793 | 0.87351
0.5 | 0.92788 | 0.97931 | 0.48930 | 0.92134 | 0.82946 | 0.92886 | 0.98052 | 0.66975 | 0.92923 | 0.87709
0.6 | 0.92867 | 0.98040 | 0.51951 | 0.92960 | 0.83954 | 0.92886 | 0.98052 | 0.67978 | 0.93427 | 0.88086
0.7 | 0.92986 | 0.98150 | 0.54688 | 0.93356 | 0.84795 | 0.92886 | 0.98052 | 0.68444 | 0.93951 | 0.88333
0.8 | 0.93006 | 0.98150 | 0.57390 | 0.93555 | 0.85525 | 0.92886 | 0.98052 | 0.67442 | 0.94190 | 0.88143
0.9 | 0.93006 | 0.98150 | 0.59632 | 0.93635 | 0.86106 | 0.92886 | 0.98052 | 0.64204 | 0.93790 | 0.87233
******** Validation loss improved from inf to 0.04961362 ********

Epoch: 2/100 |  time : 09/16/19-20:49:53
=================================================================
train_loss: 0.04913365, train_bce_loss: 0.02337285, train_dice_loss: 0.25661662, train_vae_loss: 0.04773706
valid_loss: 0.04604311, valid_bce_loss: 0.02196731, valid_dice_loss: 0.22475612, valid_vae_loss: 0.05993652
0.1 | 0.93126 | 0.98189 | 0.34080 | 0.91285 | 0.79170 | 0.92886 | 0.98052 | 0.39757 | 0.95618 | 0.81578
0.2 | 0.93126 | 0.98189 | 0.42902 | 0.91852 | 0.81517 | 0.92886 | 0.98052 | 0.48871 | 0.95720 | 0.83882
0.3 | 0.93126 | 0.98189 | 0.48857 | 0.92331 | 0.83126 | 0.92886 | 0.98052 | 0.54219 | 0.95853 | 0.85253
0.4 | 0.93126 | 0.98189 | 0.52871 | 0.92707 | 0.84224 | 0.92886 | 0.98052 | 0.57665 | 0.96037 | 0.86160
0.5 | 0.93126 | 0.98189 | 0.55911 | 0.93055 | 0.85070 | 0.92886 | 0.98052 | 0.60340 | 0.96080 | 0.86840
0.6 | 0.93126 | 0.98189 | 0.58832 | 0.93236 | 0.85846 | 0.92886 | 0.98052 | 0.62620 | 0.95800 | 0.87339
0.7 | 0.93126 | 0.98189 | 0.61111 | 0.93499 | 0.86481 | 0.92886 | 0.98052 | 0.64915 | 0.95520 | 0.87843
0.8 | 0.93126 | 0.98189 | 0.63000 | 0.93683 | 0.86999 | 0.92886 | 0.98052 | 0.66980 | 0.94989 | 0.88227
0.9 | 0.93126 | 0.98189 | 0.63744 | 0.93826 | 0.87221 | 0.92886 | 0.98052 | 0.69193 | 0.94062 | 0.88548
******** Validation loss improved from 0.04961362 to 0.04604311 ********

Epoch: 3/100 |  time : 09/16/19-21:37:49
=================================================================
train_loss: 0.04439099, train_bce_loss: 0.02134369, train_dice_loss: 0.22703889, train_vae_loss: 0.04612145
valid_loss: 0.03816676, valid_bce_loss: 0.02527659, valid_dice_loss: 0.12590236, valid_vae_loss: 0.05355251
0.1 | 0.93036 | 0.98140 | 0.47516 | 0.91958 | 0.82663 | 0.92886 | 0.98052 | 0.73389 | 0.96381 | 0.90177
0.2 | 0.93036 | 0.98140 | 0.53820 | 0.92474 | 0.84368 | 0.92886 | 0.98052 | 0.74561 | 0.96323 | 0.90456
0.3 | 0.93036 | 0.98140 | 0.57599 | 0.92834 | 0.85402 | 0.92886 | 0.98052 | 0.74529 | 0.96078 | 0.90386
0.4 | 0.93036 | 0.98140 | 0.60333 | 0.93297 | 0.86201 | 0.92886 | 0.98052 | 0.74229 | 0.95759 | 0.90231
0.5 | 0.93036 | 0.98140 | 0.62171 | 0.93631 | 0.86744 | 0.92886 | 0.98052 | 0.73847 | 0.95360 | 0.90036
0.6 | 0.93036 | 0.98140 | 0.64014 | 0.93933 | 0.87281 | 0.92886 | 0.98052 | 0.73775 | 0.94978 | 0.89923
0.7 | 0.93036 | 0.98140 | 0.65119 | 0.94010 | 0.87576 | 0.92886 | 0.98052 | 0.73007 | 0.94459 | 0.89601
0.8 | 0.93036 | 0.98140 | 0.66009 | 0.94101 | 0.87821 | 0.92886 | 0.98052 | 0.71909 | 0.93866 | 0.89178
0.9 | 0.93036 | 0.98140 | 0.65642 | 0.93981 | 0.87700 | 0.92886 | 0.98052 | 0.69019 | 0.93602 | 0.88390
******** Validation loss improved from 0.04604311 to 0.03816676 ********

Epoch: 4/100 |  time : 09/16/19-22:25:15
=================================================================
train_loss: 0.03947204, train_bce_loss: 0.02387228, train_dice_loss: 0.15817614, train_vae_loss: 0.04556601
valid_loss: 0.03813351, valid_bce_loss: 0.02181827, valid_dice_loss: 0.15293734, valid_vae_loss: 0.05385163
0.1 | 0.93066 | 0.98170 | 0.66141 | 0.93670 | 0.87762 | 0.92886 | 0.98052 | 0.69182 | 0.93619 | 0.88435
0.2 | 0.93066 | 0.98170 | 0.68237 | 0.94015 | 0.88372 | 0.92886 | 0.98052 | 0.70832 | 0.94087 | 0.88964
0.3 | 0.93066 | 0.98170 | 0.69426 | 0.94235 | 0.88724 | 0.92886 | 0.98052 | 0.71662 | 0.94306 | 0.89227
0.4 | 0.93066 | 0.98170 | 0.69969 | 0.94404 | 0.88902 | 0.92886 | 0.98052 | 0.71588 | 0.94649 | 0.89294
0.5 | 0.93066 | 0.98170 | 0.70395 | 0.94453 | 0.89021 | 0.92886 | 0.98052 | 0.71156 | 0.95068 | 0.89290
0.6 | 0.93066 | 0.98170 | 0.70502 | 0.94551 | 0.89072 | 0.92886 | 0.98052 | 0.70664 | 0.95421 | 0.89256
0.7 | 0.93066 | 0.98170 | 0.70354 | 0.94560 | 0.89038 | 0.92886 | 0.98052 | 0.69488 | 0.95563 | 0.88997
0.8 | 0.93066 | 0.98170 | 0.69741 | 0.94493 | 0.88868 | 0.92886 | 0.98052 | 0.67193 | 0.95310 | 0.88360
0.9 | 0.93066 | 0.98170 | 0.68124 | 0.94355 | 0.88429 | 0.92886 | 0.98052 | 0.62122 | 0.94523 | 0.86896
******** Validation loss improved from 0.03816676 to 0.03813351 ********

Epoch: 5/100 |  time : 09/16/19-23:12:34
=================================================================
train_loss: 0.03669771, train_bce_loss: 0.02195088, train_dice_loss: 0.14617522, train_vae_loss: 0.04519481
valid_loss: 0.03286008, valid_bce_loss: 0.02019764, valid_dice_loss: 0.11840741, valid_vae_loss: 0.04861224
0.1 | 0.93016 | 0.98140 | 0.67195 | 0.94131 | 0.88121 | 0.92886 | 0.98052 | 0.71110 | 0.95967 | 0.89504
0.2 | 0.93016 | 0.98140 | 0.69123 | 0.94539 | 0.88705 | 0.92886 | 0.98052 | 0.73081 | 0.95094 | 0.89778
0.3 | 0.93016 | 0.98140 | 0.70026 | 0.94748 | 0.88982 | 0.92886 | 0.98052 | 0.74077 | 0.94348 | 0.89841
0.4 | 0.93016 | 0.98140 | 0.70549 | 0.94888 | 0.89148 | 0.92886 | 0.98052 | 0.74625 | 0.93863 | 0.89857
0.5 | 0.93016 | 0.98140 | 0.70747 | 0.94978 | 0.89220 | 0.92886 | 0.98052 | 0.74884 | 0.93659 | 0.89870
0.6 | 0.93016 | 0.98140 | 0.70910 | 0.95006 | 0.89268 | 0.92886 | 0.98052 | 0.74950 | 0.93626 | 0.89879
0.7 | 0.93016 | 0.98140 | 0.70666 | 0.95005 | 0.89207 | 0.92886 | 0.98052 | 0.75108 | 0.93609 | 0.89914
0.8 | 0.93016 | 0.98140 | 0.70151 | 0.94887 | 0.89049 | 0.92886 | 0.98052 | 0.74864 | 0.93601 | 0.89851
0.9 | 0.93016 | 0.98140 | 0.68134 | 0.94490 | 0.88445 | 0.92886 | 0.98052 | 0.74219 | 0.93601 | 0.89690
******** Validation loss improved from 0.03813351 to 0.03286008 ********

Epoch: 6/100 |  time : 09/16/19-23:59:48
=================================================================
train_loss: 0.03337190, train_bce_loss: 0.02039215, train_dice_loss: 0.12632159, train_vae_loss: 0.04426018
valid_loss: 0.03742927, valid_bce_loss: 0.02642123, valid_dice_loss: 0.11673692, valid_vae_loss: 0.04618599
0.1 | 0.93056 | 0.98140 | 0.71597 | 0.95442 | 0.89559 | 0.92886 | 0.98052 | 0.74987 | 0.94353 | 0.90070
0.2 | 0.93056 | 0.98140 | 0.73409 | 0.95714 | 0.90080 | 0.92886 | 0.98052 | 0.75547 | 0.94200 | 0.90171
0.3 | 0.93056 | 0.98140 | 0.74237 | 0.95856 | 0.90322 | 0.92886 | 0.98052 | 0.75608 | 0.94097 | 0.90161
0.4 | 0.93056 | 0.98140 | 0.74607 | 0.95923 | 0.90431 | 0.92886 | 0.98052 | 0.75374 | 0.94047 | 0.90090
0.5 | 0.93056 | 0.98140 | 0.74713 | 0.95992 | 0.90475 | 0.92886 | 0.98052 | 0.75243 | 0.93927 | 0.90027
0.6 | 0.93056 | 0.98140 | 0.74544 | 0.96025 | 0.90441 | 0.92886 | 0.98052 | 0.74871 | 0.93878 | 0.89922
0.7 | 0.93056 | 0.98140 | 0.74085 | 0.95912 | 0.90298 | 0.92886 | 0.98052 | 0.74259 | 0.93762 | 0.89740
0.8 | 0.93056 | 0.98140 | 0.73019 | 0.95606 | 0.89955 | 0.92886 | 0.98052 | 0.73513 | 0.93640 | 0.89523
0.9 | 0.93056 | 0.98140 | 0.70420 | 0.95036 | 0.89163 | 0.92886 | 0.98052 | 0.71403 | 0.93601 | 0.88985

Epoch: 7/100 |  time : 09/17/19-00:46:43
=================================================================
train_loss: 0.03337240, train_bce_loss: 0.02030125, train_dice_loss: 0.12711928, train_vae_loss: 0.04419465
valid_loss: 0.03534311, valid_bce_loss: 0.02621537, valid_dice_loss: 0.10080388, valid_vae_loss: 0.04290432
0.1 | 0.92947 | 0.98140 | 0.70703 | 0.95655 | 0.89361 | 0.92886 | 0.98052 | 0.77248 | 0.94626 | 0.90703
0.2 | 0.92947 | 0.98140 | 0.72508 | 0.95880 | 0.89868 | 0.92886 | 0.98052 | 0.78233 | 0.94164 | 0.90834
0.3 | 0.92947 | 0.98140 | 0.73288 | 0.95998 | 0.90093 | 0.92886 | 0.98052 | 0.78381 | 0.93928 | 0.90812
0.4 | 0.92947 | 0.98140 | 0.73570 | 0.96063 | 0.90180 | 0.92886 | 0.98052 | 0.78364 | 0.93805 | 0.90777
0.5 | 0.92947 | 0.98140 | 0.73671 | 0.96080 | 0.90209 | 0.92886 | 0.98052 | 0.78146 | 0.93718 | 0.90701
0.6 | 0.92947 | 0.98140 | 0.73748 | 0.96026 | 0.90215 | 0.92886 | 0.98052 | 0.77930 | 0.93660 | 0.90632
0.7 | 0.92947 | 0.98140 | 0.73421 | 0.95929 | 0.90109 | 0.92886 | 0.98052 | 0.77413 | 0.93619 | 0.90493
0.8 | 0.92947 | 0.98140 | 0.72433 | 0.95620 | 0.89785 | 0.92886 | 0.98052 | 0.76480 | 0.93603 | 0.90255
0.9 | 0.92947 | 0.98140 | 0.69879 | 0.95030 | 0.88999 | 0.92886 | 0.98052 | 0.74523 | 0.93601 | 0.89766

Epoch: 8/100 |  time : 09/17/19-01:33:37
=================================================================
train_loss: 0.03363145, train_bce_loss: 0.02046142, train_dice_loss: 0.12850301, train_vae_loss: 0.04412011
valid_loss: 0.03402520, valid_bce_loss: 0.01858799, valid_dice_loss: 0.13964209, valid_vae_loss: 0.05190603
0.1 | 0.92957 | 0.98120 | 0.70287 | 0.95407 | 0.89192 | 0.92886 | 0.98052 | 0.63186 | 0.95739 | 0.87466
0.2 | 0.92957 | 0.98120 | 0.72068 | 0.95704 | 0.89712 | 0.92886 | 0.98052 | 0.68318 | 0.96166 | 0.88855
0.3 | 0.92957 | 0.98120 | 0.72840 | 0.95868 | 0.89946 | 0.92886 | 0.98052 | 0.70786 | 0.96337 | 0.89515
0.4 | 0.92957 | 0.98120 | 0.73256 | 0.95983 | 0.90079 | 0.92886 | 0.98052 | 0.72655 | 0.96309 | 0.89975
0.5 | 0.92957 | 0.98120 | 0.73401 | 0.96103 | 0.90145 | 0.92886 | 0.98052 | 0.73905 | 0.96407 | 0.90313
0.6 | 0.92957 | 0.98120 | 0.73210 | 0.96046 | 0.90083 | 0.92886 | 0.98052 | 0.74783 | 0.96275 | 0.90499
0.7 | 0.92957 | 0.98120 | 0.72926 | 0.95980 | 0.89995 | 0.92886 | 0.98052 | 0.74891 | 0.96051 | 0.90470
0.8 | 0.92957 | 0.98120 | 0.72145 | 0.95723 | 0.89736 | 0.92886 | 0.98052 | 0.74363 | 0.95426 | 0.90182
0.9 | 0.92957 | 0.98120 | 0.69885 | 0.95198 | 0.89040 | 0.92886 | 0.98052 | 0.72283 | 0.94128 | 0.89337

Epoch: 9/100 |  time : 09/17/19-02:20:32
=================================================================
train_loss: 0.03300786, train_bce_loss: 0.02016044, train_dice_loss: 0.12522852, train_vae_loss: 0.04356651
valid_loss: 0.03106421, valid_bce_loss: 0.01999748, valid_dice_loss: 0.11001434, valid_vae_loss: 0.04064790
0.1 | 0.93046 | 0.98140 | 0.71193 | 0.95283 | 0.89415 | 0.92886 | 0.98052 | 0.78639 | 0.94569 | 0.91036
0.2 | 0.93046 | 0.98140 | 0.72838 | 0.95579 | 0.89901 | 0.92886 | 0.98052 | 0.79101 | 0.95118 | 0.91289
0.3 | 0.93046 | 0.98140 | 0.73647 | 0.95759 | 0.90148 | 0.92886 | 0.98052 | 0.78783 | 0.95465 | 0.91297
0.4 | 0.93046 | 0.98140 | 0.73900 | 0.95834 | 0.90230 | 0.92886 | 0.98052 | 0.78409 | 0.95930 | 0.91319
0.5 | 0.93046 | 0.98140 | 0.74023 | 0.95857 | 0.90266 | 0.92886 | 0.98052 | 0.77725 | 0.96360 | 0.91256
0.6 | 0.93046 | 0.98140 | 0.74081 | 0.95866 | 0.90283 | 0.92886 | 0.98052 | 0.76627 | 0.96483 | 0.91012
0.7 | 0.93046 | 0.98140 | 0.73519 | 0.95773 | 0.90119 | 0.92886 | 0.98052 | 0.75298 | 0.96677 | 0.90728
0.8 | 0.93046 | 0.98140 | 0.72682 | 0.95563 | 0.89858 | 0.92886 | 0.98052 | 0.73343 | 0.96707 | 0.90247
0.9 | 0.93046 | 0.98140 | 0.70477 | 0.95012 | 0.89169 | 0.92886 | 0.98052 | 0.69493 | 0.96170 | 0.89150
******** Validation loss improved from 0.03286008 to 0.03106421 ********

Epoch: 10/100 |  time : 09/17/19-03:07:35
=================================================================
train_loss: 0.03123091, train_bce_loss: 0.01890380, train_dice_loss: 0.11790697, train_vae_loss: 0.04317170
valid_loss: 0.02859567, valid_bce_loss: 0.01861306, valid_dice_loss: 0.09037369, valid_vae_loss: 0.04667849
0.1 | 0.93046 | 0.98120 | 0.72566 | 0.95536 | 0.89817 | 0.92886 | 0.98052 | 0.77395 | 0.96966 | 0.91325
0.2 | 0.93046 | 0.98120 | 0.74209 | 0.95884 | 0.90315 | 0.92886 | 0.98052 | 0.79397 | 0.97071 | 0.91852
0.3 | 0.93046 | 0.98120 | 0.74903 | 0.96085 | 0.90538 | 0.92886 | 0.98052 | 0.80234 | 0.96986 | 0.92039
0.4 | 0.93046 | 0.98120 | 0.75204 | 0.96236 | 0.90651 | 0.92886 | 0.98052 | 0.80742 | 0.96832 | 0.92128
0.5 | 0.93046 | 0.98120 | 0.75271 | 0.96211 | 0.90662 | 0.92886 | 0.98052 | 0.80826 | 0.96612 | 0.92094
0.6 | 0.93046 | 0.98120 | 0.75122 | 0.96216 | 0.90626 | 0.92886 | 0.98052 | 0.80781 | 0.96392 | 0.92028
0.7 | 0.93046 | 0.98120 | 0.74724 | 0.96135 | 0.90506 | 0.92886 | 0.98052 | 0.80525 | 0.96078 | 0.91885
0.8 | 0.93046 | 0.98120 | 0.73698 | 0.95840 | 0.90176 | 0.92886 | 0.98052 | 0.80031 | 0.95802 | 0.91693
0.9 | 0.93046 | 0.98120 | 0.71317 | 0.95330 | 0.89453 | 0.92886 | 0.98052 | 0.78541 | 0.95253 | 0.91183
******** Validation loss improved from 0.03106421 to 0.02859567 ********

Epoch: 11/100 |  time : 09/17/19-03:54:36
=================================================================
train_loss: 0.03136040, train_bce_loss: 0.01922413, train_dice_loss: 0.11701743, train_vae_loss: 0.04279357
valid_loss: 0.03102213, valid_bce_loss: 0.02193232, valid_dice_loss: 0.09478964, valid_vae_loss: 0.03997309
0.1 | 0.92977 | 0.98150 | 0.72921 | 0.95880 | 0.89982 | 0.92886 | 0.98052 | 0.80199 | 0.96872 | 0.92002
0.2 | 0.92977 | 0.98150 | 0.74494 | 0.96148 | 0.90442 | 0.92886 | 0.98052 | 0.80440 | 0.96209 | 0.91897
0.3 | 0.92977 | 0.98150 | 0.75245 | 0.96325 | 0.90674 | 0.92886 | 0.98052 | 0.80302 | 0.95656 | 0.91724
0.4 | 0.92977 | 0.98150 | 0.75611 | 0.96364 | 0.90775 | 0.92886 | 0.98052 | 0.80082 | 0.95220 | 0.91560
0.5 | 0.92977 | 0.98150 | 0.75530 | 0.96383 | 0.90760 | 0.92886 | 0.98052 | 0.79778 | 0.94937 | 0.91413
0.6 | 0.92977 | 0.98150 | 0.75337 | 0.96367 | 0.90707 | 0.92886 | 0.98052 | 0.79349 | 0.94599 | 0.91222
0.7 | 0.92977 | 0.98150 | 0.74810 | 0.96322 | 0.90565 | 0.92886 | 0.98052 | 0.78806 | 0.94275 | 0.91005
0.8 | 0.92977 | 0.98150 | 0.73948 | 0.96002 | 0.90269 | 0.92886 | 0.98052 | 0.77812 | 0.93926 | 0.90669
0.9 | 0.92977 | 0.98150 | 0.71387 | 0.95406 | 0.89480 | 0.92886 | 0.98052 | 0.74419 | 0.93626 | 0.89746

Epoch: 12/100 |  time : 09/17/19-04:40:58
=================================================================
train_loss: 0.03165591, train_bce_loss: 0.01926679, train_dice_loss: 0.11974689, train_vae_loss: 0.04267786
valid_loss: 0.02964209, valid_bce_loss: 0.01888933, valid_dice_loss: 0.10336637, valid_vae_loss: 0.04193990
0.1 | 0.93036 | 0.98140 | 0.72794 | 0.95215 | 0.89796 | 0.92886 | 0.98052 | 0.77489 | 0.95161 | 0.90897
0.2 | 0.93036 | 0.98140 | 0.74370 | 0.95646 | 0.90298 | 0.92886 | 0.98052 | 0.78921 | 0.95759 | 0.91404
0.3 | 0.93036 | 0.98140 | 0.74931 | 0.95806 | 0.90478 | 0.92886 | 0.98052 | 0.79489 | 0.95771 | 0.91550
0.4 | 0.93036 | 0.98140 | 0.75327 | 0.95898 | 0.90600 | 0.92886 | 0.98052 | 0.79569 | 0.95868 | 0.91594
0.5 | 0.93036 | 0.98140 | 0.75374 | 0.95941 | 0.90623 | 0.92886 | 0.98052 | 0.79567 | 0.95773 | 0.91569
0.6 | 0.93036 | 0.98140 | 0.75194 | 0.95904 | 0.90569 | 0.92886 | 0.98052 | 0.79464 | 0.95628 | 0.91508
0.7 | 0.93036 | 0.98140 | 0.74659 | 0.95891 | 0.90431 | 0.92886 | 0.98052 | 0.79327 | 0.95219 | 0.91371
0.8 | 0.93036 | 0.98140 | 0.73832 | 0.95803 | 0.90203 | 0.92886 | 0.98052 | 0.78583 | 0.94401 | 0.90981
0.9 | 0.93036 | 0.98140 | 0.71359 | 0.95291 | 0.89456 | 0.92886 | 0.98052 | 0.76965 | 0.93753 | 0.90414

Epoch: 13/100 |  time : 09/17/19-05:27:44
=================================================================
train_loss: 0.03159356, train_bce_loss: 0.01916625, train_dice_loss: 0.12022257, train_vae_loss: 0.04238297
valid_loss: 0.02816971, valid_bce_loss: 0.01880126, valid_dice_loss: 0.08897163, valid_vae_loss: 0.04231542
0.1 | 0.93096 | 0.98060 | 0.71890 | 0.95626 | 0.89668 | 0.92886 | 0.98052 | 0.79263 | 0.96781 | 0.91746
0.2 | 0.93096 | 0.98060 | 0.73474 | 0.95988 | 0.90155 | 0.92886 | 0.98052 | 0.80473 | 0.96957 | 0.92092
0.3 | 0.93096 | 0.98060 | 0.74280 | 0.96116 | 0.90388 | 0.92886 | 0.98052 | 0.80838 | 0.97096 | 0.92218
0.4 | 0.93096 | 0.98060 | 0.74481 | 0.96143 | 0.90445 | 0.92886 | 0.98052 | 0.80930 | 0.97127 | 0.92249
0.5 | 0.93096 | 0.98060 | 0.74570 | 0.96198 | 0.90481 | 0.92886 | 0.98052 | 0.80850 | 0.97201 | 0.92247
0.6 | 0.93096 | 0.98060 | 0.74517 | 0.96268 | 0.90485 | 0.92886 | 0.98052 | 0.80615 | 0.97158 | 0.92178
0.7 | 0.93096 | 0.98060 | 0.74253 | 0.96147 | 0.90389 | 0.92886 | 0.98052 | 0.80333 | 0.97084 | 0.92089
0.8 | 0.93096 | 0.98060 | 0.73455 | 0.95931 | 0.90135 | 0.92886 | 0.98052 | 0.79540 | 0.96931 | 0.91852
0.9 | 0.93096 | 0.98060 | 0.71120 | 0.95388 | 0.89416 | 0.92886 | 0.98052 | 0.77242 | 0.96465 | 0.91161
******** Validation loss improved from 0.02859567 to 0.02816971 ********

Epoch: 14/100 |  time : 09/17/19-06:14:47
=================================================================
train_loss: 0.03087311, train_bce_loss: 0.01880129, train_dice_loss: 0.11589101, train_vae_loss: 0.04242976
valid_loss: 0.02777267, valid_bce_loss: 0.01788196, valid_dice_loss: 0.09384105, valid_vae_loss: 0.04082997
0.1 | 0.92967 | 0.98140 | 0.73058 | 0.96059 | 0.90056 | 0.92886 | 0.98052 | 0.78257 | 0.97186 | 0.91595
0.2 | 0.92967 | 0.98140 | 0.74733 | 0.96350 | 0.90547 | 0.92886 | 0.98052 | 0.79582 | 0.97192 | 0.91928
0.3 | 0.92967 | 0.98140 | 0.75387 | 0.96465 | 0.90740 | 0.92886 | 0.98052 | 0.79902 | 0.97023 | 0.91966
0.4 | 0.92967 | 0.98140 | 0.75642 | 0.96478 | 0.90807 | 0.92886 | 0.98052 | 0.79957 | 0.96804 | 0.91925
0.5 | 0.92967 | 0.98140 | 0.75713 | 0.96471 | 0.90823 | 0.92886 | 0.98052 | 0.79884 | 0.96462 | 0.91821
0.6 | 0.92967 | 0.98140 | 0.75611 | 0.96441 | 0.90790 | 0.92886 | 0.98052 | 0.79557 | 0.96062 | 0.91639
0.7 | 0.92967 | 0.98140 | 0.75233 | 0.96312 | 0.90663 | 0.92886 | 0.98052 | 0.78927 | 0.95612 | 0.91369
0.8 | 0.92967 | 0.98140 | 0.74427 | 0.96028 | 0.90390 | 0.92886 | 0.98052 | 0.78217 | 0.95029 | 0.91046
0.9 | 0.92967 | 0.98140 | 0.71907 | 0.95482 | 0.89624 | 0.92886 | 0.98052 | 0.76018 | 0.94085 | 0.90260
******** Validation loss improved from 0.02816971 to 0.02777267 ********

Epoch: 15/100 |  time : 09/17/19-07:01:19
=================================================================
train_loss: 0.02879874, train_bce_loss: 0.01739524, train_dice_loss: 0.10686710, train_vae_loss: 0.04195844
valid_loss: 0.02597581, valid_bce_loss: 0.01621329, valid_dice_loss: 0.08907179, valid_vae_loss: 0.04098004
0.1 | 0.92937 | 0.98110 | 0.75368 | 0.96145 | 0.90640 | 0.92886 | 0.98052 | 0.79466 | 0.97080 | 0.91871
0.2 | 0.92937 | 0.98110 | 0.76899 | 0.96402 | 0.91087 | 0.92886 | 0.98052 | 0.80586 | 0.97418 | 0.92235
0.3 | 0.92937 | 0.98110 | 0.77552 | 0.96536 | 0.91284 | 0.92886 | 0.98052 | 0.80972 | 0.97427 | 0.92334
0.4 | 0.92937 | 0.98110 | 0.77754 | 0.96616 | 0.91354 | 0.92886 | 0.98052 | 0.81110 | 0.97559 | 0.92402
0.5 | 0.92937 | 0.98110 | 0.77791 | 0.96620 | 0.91364 | 0.92886 | 0.98052 | 0.81071 | 0.97539 | 0.92387
0.6 | 0.92937 | 0.98110 | 0.77591 | 0.96587 | 0.91306 | 0.92886 | 0.98052 | 0.80832 | 0.97429 | 0.92300
0.7 | 0.92937 | 0.98110 | 0.77056 | 0.96457 | 0.91140 | 0.92886 | 0.98052 | 0.80392 | 0.97259 | 0.92147
0.8 | 0.92937 | 0.98110 | 0.75952 | 0.96230 | 0.90807 | 0.92886 | 0.98052 | 0.79401 | 0.96911 | 0.91812
0.9 | 0.92937 | 0.98110 | 0.73072 | 0.95685 | 0.89951 | 0.92886 | 0.98052 | 0.77027 | 0.95874 | 0.90960
******** Validation loss improved from 0.02777267 to 0.02597581 ********

Epoch: 16/100 |  time : 09/17/19-07:47:28
=================================================================
train_loss: 0.02965735, train_bce_loss: 0.01816715, train_dice_loss: 0.10921632, train_vae_loss: 0.04202001
valid_loss: 0.02847040, valid_bce_loss: 0.01740540, valid_dice_loss: 0.10553736, valid_vae_loss: 0.03992348
0.1 | 0.93046 | 0.98170 | 0.74560 | 0.96073 | 0.90462 | 0.92886 | 0.98052 | 0.72209 | 0.96852 | 0.90000
0.2 | 0.93046 | 0.98170 | 0.76055 | 0.96356 | 0.90907 | 0.92886 | 0.98052 | 0.74840 | 0.97042 | 0.90705
0.3 | 0.93046 | 0.98170 | 0.76734 | 0.96490 | 0.91110 | 0.92886 | 0.98052 | 0.75846 | 0.97159 | 0.90986
0.4 | 0.93046 | 0.98170 | 0.77094 | 0.96532 | 0.91210 | 0.92886 | 0.98052 | 0.76342 | 0.97294 | 0.91143
0.5 | 0.93046 | 0.98170 | 0.77188 | 0.96522 | 0.91231 | 0.92886 | 0.98052 | 0.76711 | 0.97331 | 0.91245
0.6 | 0.93046 | 0.98170 | 0.76972 | 0.96456 | 0.91161 | 0.92886 | 0.98052 | 0.77013 | 0.97378 | 0.91332
0.7 | 0.93046 | 0.98170 | 0.76482 | 0.96396 | 0.91024 | 0.92886 | 0.98052 | 0.77015 | 0.97389 | 0.91336
0.8 | 0.93046 | 0.98170 | 0.75539 | 0.96145 | 0.90725 | 0.92886 | 0.98052 | 0.76976 | 0.97283 | 0.91299
0.9 | 0.93046 | 0.98170 | 0.72994 | 0.95586 | 0.89949 | 0.92886 | 0.98052 | 0.76506 | 0.97087 | 0.91133

Epoch: 17/100 |  time : 09/17/19-08:34:12
=================================================================
train_loss: 0.02993470, train_bce_loss: 0.01820393, train_dice_loss: 0.11171865, train_vae_loss: 0.04199693
valid_loss: 0.02786239, valid_bce_loss: 0.01737718, valid_dice_loss: 0.09605622, valid_vae_loss: 0.04355023
0.1 | 0.93076 | 0.98150 | 0.74392 | 0.95621 | 0.90310 | 0.92886 | 0.98052 | 0.77637 | 0.95773 | 0.91087
0.2 | 0.93076 | 0.98150 | 0.75953 | 0.96026 | 0.90801 | 0.92886 | 0.98052 | 0.79332 | 0.96338 | 0.91652
0.3 | 0.93076 | 0.98150 | 0.76651 | 0.96150 | 0.91007 | 0.92886 | 0.98052 | 0.79969 | 0.96798 | 0.91926
0.4 | 0.93076 | 0.98150 | 0.76976 | 0.96240 | 0.91111 | 0.92886 | 0.98052 | 0.80257 | 0.96869 | 0.92016
0.5 | 0.93076 | 0.98150 | 0.76906 | 0.96378 | 0.91127 | 0.92886 | 0.98052 | 0.80309 | 0.96978 | 0.92056
0.6 | 0.93076 | 0.98150 | 0.76674 | 0.96378 | 0.91069 | 0.92886 | 0.98052 | 0.80182 | 0.96945 | 0.92016
0.7 | 0.93076 | 0.98150 | 0.76239 | 0.96401 | 0.90966 | 0.92886 | 0.98052 | 0.79717 | 0.96688 | 0.91836
0.8 | 0.93076 | 0.98150 | 0.75156 | 0.96224 | 0.90652 | 0.92886 | 0.98052 | 0.78493 | 0.96413 | 0.91461
0.9 | 0.93076 | 0.98150 | 0.72434 | 0.95649 | 0.89827 | 0.92886 | 0.98052 | 0.75795 | 0.95628 | 0.90590

Epoch: 18/100 |  time : 09/17/19-09:21:07
=================================================================
train_loss: 0.03126480, train_bce_loss: 0.01910790, train_dice_loss: 0.11787441, train_vae_loss: 0.04191041
valid_loss: 0.02708624, valid_bce_loss: 0.01645079, valid_dice_loss: 0.10064824, valid_vae_loss: 0.03860791
0.1 | 0.93036 | 0.98120 | 0.72354 | 0.95716 | 0.89806 | 0.92886 | 0.98052 | 0.77479 | 0.96066 | 0.91121
0.2 | 0.93036 | 0.98120 | 0.73990 | 0.95993 | 0.90285 | 0.92886 | 0.98052 | 0.78811 | 0.96552 | 0.91575
0.3 | 0.93036 | 0.98120 | 0.74644 | 0.96150 | 0.90488 | 0.92886 | 0.98052 | 0.78999 | 0.96692 | 0.91657
0.4 | 0.93036 | 0.98120 | 0.74990 | 0.96257 | 0.90601 | 0.92886 | 0.98052 | 0.79127 | 0.96857 | 0.91731
0.5 | 0.93036 | 0.98120 | 0.75205 | 0.96346 | 0.90677 | 0.92886 | 0.98052 | 0.78781 | 0.97073 | 0.91698
0.6 | 0.93036 | 0.98120 | 0.75018 | 0.96397 | 0.90643 | 0.92886 | 0.98052 | 0.78277 | 0.97165 | 0.91595
0.7 | 0.93036 | 0.98120 | 0.74482 | 0.96283 | 0.90480 | 0.92886 | 0.98052 | 0.77515 | 0.96970 | 0.91356
0.8 | 0.93036 | 0.98120 | 0.73593 | 0.95992 | 0.90185 | 0.92886 | 0.98052 | 0.76089 | 0.96567 | 0.90898
0.9 | 0.93036 | 0.98120 | 0.71078 | 0.95312 | 0.89387 | 0.92886 | 0.98052 | 0.72629 | 0.95473 | 0.89760

Epoch: 19/100 |  time : 09/17/19-10:08:02
=================================================================
train_loss: 0.03006811, train_bce_loss: 0.01817329, train_dice_loss: 0.11367556, train_vae_loss: 0.04161926
valid_loss: 0.02638485, valid_bce_loss: 0.01603954, valid_dice_loss: 0.09481303, valid_vae_loss: 0.04071913
0.1 | 0.93106 | 0.98179 | 0.73627 | 0.95761 | 0.90169 | 0.92886 | 0.98052 | 0.76763 | 0.96796 | 0.91124
0.2 | 0.93106 | 0.98179 | 0.75280 | 0.96029 | 0.90649 | 0.92886 | 0.98052 | 0.78372 | 0.97170 | 0.91620
0.3 | 0.93106 | 0.98179 | 0.75947 | 0.96247 | 0.90870 | 0.92886 | 0.98052 | 0.78882 | 0.97362 | 0.91795
0.4 | 0.93106 | 0.98179 | 0.76193 | 0.96412 | 0.90973 | 0.92886 | 0.98052 | 0.79089 | 0.97442 | 0.91867
0.5 | 0.93106 | 0.98179 | 0.76393 | 0.96449 | 0.91032 | 0.92886 | 0.98052 | 0.79253 | 0.97556 | 0.91937
0.6 | 0.93106 | 0.98179 | 0.76303 | 0.96401 | 0.90997 | 0.92886 | 0.98052 | 0.78990 | 0.97676 | 0.91901
0.7 | 0.93106 | 0.98179 | 0.75868 | 0.96286 | 0.90860 | 0.92886 | 0.98052 | 0.78513 | 0.97640 | 0.91773
0.8 | 0.93106 | 0.98179 | 0.75098 | 0.95939 | 0.90581 | 0.92886 | 0.98052 | 0.77738 | 0.97412 | 0.91522
0.9 | 0.93106 | 0.98179 | 0.72605 | 0.95341 | 0.89808 | 0.92886 | 0.98052 | 0.75525 | 0.96899 | 0.90840

Epoch: 20/100 |  time : 09/17/19-10:54:57
=================================================================
train_loss: 0.02813135, train_bce_loss: 0.01688276, train_dice_loss: 0.10480976, train_vae_loss: 0.04144167
valid_loss: 0.02756123, valid_bce_loss: 0.01671684, valid_dice_loss: 0.09766041, valid_vae_loss: 0.04421716
0.1 | 0.93036 | 0.98170 | 0.75459 | 0.96420 | 0.90771 | 0.92886 | 0.98052 | 0.77208 | 0.97121 | 0.91317
0.2 | 0.93036 | 0.98170 | 0.76983 | 0.96665 | 0.91214 | 0.92886 | 0.98052 | 0.79306 | 0.97274 | 0.91880
0.3 | 0.93036 | 0.98170 | 0.77593 | 0.96817 | 0.91404 | 0.92886 | 0.98052 | 0.79932 | 0.97322 | 0.92048
0.4 | 0.93036 | 0.98170 | 0.77811 | 0.96940 | 0.91489 | 0.92886 | 0.98052 | 0.79920 | 0.97323 | 0.92045
0.5 | 0.93036 | 0.98170 | 0.77862 | 0.97013 | 0.91520 | 0.92886 | 0.98052 | 0.79666 | 0.97288 | 0.91973
0.6 | 0.93036 | 0.98170 | 0.77742 | 0.97021 | 0.91492 | 0.92886 | 0.98052 | 0.78985 | 0.97211 | 0.91784
0.7 | 0.93036 | 0.98170 | 0.77314 | 0.96928 | 0.91362 | 0.92886 | 0.98052 | 0.78073 | 0.97090 | 0.91525
0.8 | 0.93036 | 0.98170 | 0.76328 | 0.96714 | 0.91062 | 0.92886 | 0.98052 | 0.76144 | 0.96873 | 0.90989
0.9 | 0.93036 | 0.98170 | 0.73628 | 0.96123 | 0.90239 | 0.92886 | 0.98052 | 0.72295 | 0.96355 | 0.89897

Epoch: 21/100 |  time : 09/17/19-11:41:50
=================================================================
train_loss: 0.02901120, train_bce_loss: 0.01737061, train_dice_loss: 0.10953712, train_vae_loss: 0.04160997
valid_loss: 0.02687919, valid_bce_loss: 0.01666252, valid_dice_loss: 0.09410760, valid_vae_loss: 0.04138412
0.1 | 0.93026 | 0.98110 | 0.74738 | 0.95864 | 0.90434 | 0.92886 | 0.98052 | 0.78284 | 0.96214 | 0.91359
0.2 | 0.93026 | 0.98110 | 0.76306 | 0.96229 | 0.90918 | 0.92886 | 0.98052 | 0.80077 | 0.96862 | 0.91969
0.3 | 0.93026 | 0.98110 | 0.76980 | 0.96356 | 0.91118 | 0.92886 | 0.98052 | 0.80537 | 0.97155 | 0.92157
0.4 | 0.93026 | 0.98110 | 0.77247 | 0.96416 | 0.91200 | 0.92886 | 0.98052 | 0.80600 | 0.97361 | 0.92225
0.5 | 0.93026 | 0.98110 | 0.77391 | 0.96413 | 0.91235 | 0.92886 | 0.98052 | 0.80303 | 0.97442 | 0.92171
0.6 | 0.93026 | 0.98110 | 0.77249 | 0.96436 | 0.91205 | 0.92886 | 0.98052 | 0.79671 | 0.97613 | 0.92055
0.7 | 0.93026 | 0.98110 | 0.76768 | 0.96378 | 0.91071 | 0.92886 | 0.98052 | 0.78642 | 0.97605 | 0.91796
0.8 | 0.93026 | 0.98110 | 0.75812 | 0.96129 | 0.90769 | 0.92886 | 0.98052 | 0.77155 | 0.97575 | 0.91417
0.9 | 0.93026 | 0.98110 | 0.73175 | 0.95623 | 0.89984 | 0.92886 | 0.98052 | 0.74025 | 0.97272 | 0.90559

Epoch: 22/100 |  time : 09/17/19-12:28:07
=================================================================
train_loss: 0.02909105, train_bce_loss: 0.01754061, train_dice_loss: 0.10926519, train_vae_loss: 0.04132046
valid_loss: 0.02660501, valid_bce_loss: 0.01727048, valid_dice_loss: 0.08898303, valid_vae_loss: 0.03890320
0.1 | 0.93076 | 0.98150 | 0.74434 | 0.96034 | 0.90423 | 0.92886 | 0.98052 | 0.78949 | 0.97223 | 0.91777
0.2 | 0.93076 | 0.98150 | 0.76199 | 0.96308 | 0.90933 | 0.92886 | 0.98052 | 0.80243 | 0.97336 | 0.92129
0.3 | 0.93076 | 0.98150 | 0.76920 | 0.96483 | 0.91157 | 0.92886 | 0.98052 | 0.80694 | 0.97369 | 0.92250
0.4 | 0.93076 | 0.98150 | 0.77278 | 0.96523 | 0.91257 | 0.92886 | 0.98052 | 0.80874 | 0.97355 | 0.92292
0.5 | 0.93076 | 0.98150 | 0.77379 | 0.96517 | 0.91281 | 0.92886 | 0.98052 | 0.80913 | 0.97265 | 0.92279
0.6 | 0.93076 | 0.98150 | 0.77138 | 0.96475 | 0.91210 | 0.92886 | 0.98052 | 0.80819 | 0.97121 | 0.92220
0.7 | 0.93076 | 0.98150 | 0.76813 | 0.96365 | 0.91101 | 0.92886 | 0.98052 | 0.80565 | 0.96991 | 0.92124
0.8 | 0.93076 | 0.98150 | 0.75994 | 0.96160 | 0.90845 | 0.92886 | 0.98052 | 0.79961 | 0.96679 | 0.91894
0.9 | 0.93076 | 0.98150 | 0.73320 | 0.95673 | 0.90055 | 0.92886 | 0.98052 | 0.78534 | 0.96105 | 0.91394

Epoch: 23/100 |  time : 09/17/19-13:14:31
=================================================================
train_loss: 0.03082482, train_bce_loss: 0.01847684, train_dice_loss: 0.11902817, train_vae_loss: 0.04140531
valid_loss: 0.03101481, valid_bce_loss: 0.02160086, valid_dice_loss: 0.09200712, valid_vae_loss: 0.04533418
0.1 | 0.93036 | 0.98150 | 0.72270 | 0.95517 | 0.89743 | 0.92886 | 0.98052 | 0.80941 | 0.97003 | 0.92221
0.2 | 0.93036 | 0.98150 | 0.73931 | 0.95815 | 0.90233 | 0.92886 | 0.98052 | 0.80951 | 0.97161 | 0.92263
0.3 | 0.93036 | 0.98150 | 0.74697 | 0.96007 | 0.90472 | 0.92886 | 0.98052 | 0.80130 | 0.97181 | 0.92062
0.4 | 0.93036 | 0.98150 | 0.75123 | 0.96103 | 0.90603 | 0.92886 | 0.98052 | 0.79143 | 0.97171 | 0.91813
0.5 | 0.93036 | 0.98150 | 0.75232 | 0.96188 | 0.90652 | 0.92886 | 0.98052 | 0.77969 | 0.97140 | 0.91512
0.6 | 0.93036 | 0.98150 | 0.75136 | 0.96173 | 0.90624 | 0.92886 | 0.98052 | 0.76423 | 0.97127 | 0.91122
0.7 | 0.93036 | 0.98150 | 0.74890 | 0.96102 | 0.90544 | 0.92886 | 0.98052 | 0.74457 | 0.96996 | 0.90598
0.8 | 0.93036 | 0.98150 | 0.74138 | 0.95884 | 0.90302 | 0.92886 | 0.98052 | 0.71634 | 0.96789 | 0.89840
0.9 | 0.93036 | 0.98150 | 0.71659 | 0.95352 | 0.89549 | 0.92886 | 0.98052 | 0.66854 | 0.96399 | 0.88548

Epoch: 24/100 |  time : 09/17/19-14:00:51
=================================================================
train_loss: 0.03105082, train_bce_loss: 0.01867380, train_dice_loss: 0.11961793, train_vae_loss: 0.04149983
valid_loss: 0.02850738, valid_bce_loss: 0.01944309, valid_dice_loss: 0.08890995, valid_vae_loss: 0.04061915
0.1 | 0.93006 | 0.98160 | 0.71619 | 0.95867 | 0.89663 | 0.92886 | 0.98052 | 0.79032 | 0.97528 | 0.91874
0.2 | 0.93006 | 0.98160 | 0.73329 | 0.96185 | 0.90170 | 0.92886 | 0.98052 | 0.80132 | 0.97409 | 0.92120
0.3 | 0.93006 | 0.98160 | 0.74085 | 0.96375 | 0.90406 | 0.92886 | 0.98052 | 0.80481 | 0.97214 | 0.92158
0.4 | 0.93006 | 0.98160 | 0.74413 | 0.96466 | 0.90511 | 0.92886 | 0.98052 | 0.80573 | 0.96951 | 0.92116
0.5 | 0.93006 | 0.98160 | 0.74622 | 0.96441 | 0.90557 | 0.92886 | 0.98052 | 0.80600 | 0.96727 | 0.92066
0.6 | 0.93006 | 0.98160 | 0.74735 | 0.96463 | 0.90591 | 0.92886 | 0.98052 | 0.80428 | 0.96350 | 0.91929
0.7 | 0.93006 | 0.98160 | 0.74407 | 0.96374 | 0.90487 | 0.92886 | 0.98052 | 0.79940 | 0.95889 | 0.91692
0.8 | 0.93006 | 0.98160 | 0.74056 | 0.96202 | 0.90356 | 0.92886 | 0.98052 | 0.79138 | 0.95299 | 0.91344
0.9 | 0.93006 | 0.98160 | 0.71816 | 0.95670 | 0.89663 | 0.92886 | 0.98052 | 0.76683 | 0.94531 | 0.90538

Epoch: 25/100 |  time : 09/17/19-14:47:14
=================================================================
train_loss: 0.02876780, train_bce_loss: 0.01734237, train_dice_loss: 0.10791953, train_vae_loss: 0.04101948
valid_loss: 0.02783618, valid_bce_loss: 0.01825520, valid_dice_loss: 0.09254408, valid_vae_loss: 0.03977611
0.1 | 0.93076 | 0.98170 | 0.74985 | 0.96107 | 0.90584 | 0.92886 | 0.98052 | 0.76326 | 0.96858 | 0.91030
0.2 | 0.93076 | 0.98170 | 0.76609 | 0.96436 | 0.91073 | 0.92886 | 0.98052 | 0.78829 | 0.96937 | 0.91676
0.3 | 0.93076 | 0.98170 | 0.77306 | 0.96578 | 0.91282 | 0.92886 | 0.98052 | 0.80137 | 0.96919 | 0.91999
0.4 | 0.93076 | 0.98170 | 0.77622 | 0.96653 | 0.91380 | 0.92886 | 0.98052 | 0.80826 | 0.96869 | 0.92158
0.5 | 0.93076 | 0.98170 | 0.77681 | 0.96690 | 0.91404 | 0.92886 | 0.98052 | 0.81215 | 0.96777 | 0.92232
0.6 | 0.93076 | 0.98170 | 0.77618 | 0.96664 | 0.91382 | 0.92886 | 0.98052 | 0.81191 | 0.96638 | 0.92192
0.7 | 0.93076 | 0.98170 | 0.77172 | 0.96579 | 0.91249 | 0.92886 | 0.98052 | 0.80889 | 0.96450 | 0.92069
0.8 | 0.93076 | 0.98170 | 0.76364 | 0.96354 | 0.90991 | 0.92886 | 0.98052 | 0.79630 | 0.96157 | 0.91681
0.9 | 0.93076 | 0.98170 | 0.73903 | 0.95694 | 0.90211 | 0.92886 | 0.98052 | 0.77158 | 0.95612 | 0.90927

Epoch: 26/100 |  time : 09/17/19-15:33:57
=================================================================
train_loss: 0.02876228, train_bce_loss: 0.01694516, train_dice_loss: 0.11084326, train_vae_loss: 0.04121828
valid_loss: 0.03347953, valid_bce_loss: 0.02235431, valid_dice_loss: 0.11337399, valid_vae_loss: 0.04258674
0.1 | 0.93056 | 0.98110 | 0.73659 | 0.96133 | 0.90239 | 0.92886 | 0.98052 | 0.77587 | 0.93329 | 0.90464
0.2 | 0.93056 | 0.98110 | 0.75348 | 0.96368 | 0.90721 | 0.92886 | 0.98052 | 0.77404 | 0.93920 | 0.90566
0.3 | 0.93056 | 0.98110 | 0.75924 | 0.96496 | 0.90897 | 0.92886 | 0.98052 | 0.76989 | 0.94460 | 0.90597
0.4 | 0.93056 | 0.98110 | 0.76211 | 0.96673 | 0.91012 | 0.92886 | 0.98052 | 0.76441 | 0.94757 | 0.90534
0.5 | 0.93056 | 0.98110 | 0.76321 | 0.96663 | 0.91037 | 0.92886 | 0.98052 | 0.75726 | 0.95033 | 0.90424
0.6 | 0.93056 | 0.98110 | 0.76267 | 0.96616 | 0.91012 | 0.92886 | 0.98052 | 0.75195 | 0.95153 | 0.90322
0.7 | 0.93056 | 0.98110 | 0.75843 | 0.96512 | 0.90880 | 0.92886 | 0.98052 | 0.74395 | 0.95480 | 0.90203
0.8 | 0.93056 | 0.98110 | 0.75195 | 0.96252 | 0.90653 | 0.92886 | 0.98052 | 0.73187 | 0.95813 | 0.89985
0.9 | 0.93056 | 0.98110 | 0.72665 | 0.95730 | 0.89890 | 0.92886 | 0.98052 | 0.70481 | 0.95787 | 0.89301
Epoch    25: reducing learning rate of group 0 to 1.0000e-03.

Epoch: 27/100 |  time : 09/17/19-16:20:48
=================================================================
train_loss: 0.02474583, train_bce_loss: 0.01404478, train_dice_loss: 0.09421544, train_vae_loss: 0.04088468
valid_loss: 0.02520458, valid_bce_loss: 0.01519063, valid_dice_loss: 0.08616177, valid_vae_loss: 0.04435896
0.1 | 0.93016 | 0.98110 | 0.78092 | 0.96893 | 0.91528 | 0.92886 | 0.98052 | 0.79987 | 0.97569 | 0.92124
0.2 | 0.93016 | 0.98110 | 0.79641 | 0.97171 | 0.91985 | 0.92886 | 0.98052 | 0.81290 | 0.97701 | 0.92482
0.3 | 0.93016 | 0.98110 | 0.80245 | 0.97292 | 0.92166 | 0.92886 | 0.98052 | 0.81731 | 0.97673 | 0.92586
0.4 | 0.93016 | 0.98110 | 0.80494 | 0.97350 | 0.92242 | 0.92886 | 0.98052 | 0.81814 | 0.97573 | 0.92581
0.5 | 0.93016 | 0.98110 | 0.80444 | 0.97403 | 0.92243 | 0.92886 | 0.98052 | 0.81821 | 0.97426 | 0.92546
0.6 | 0.93016 | 0.98110 | 0.80238 | 0.97379 | 0.92186 | 0.92886 | 0.98052 | 0.81224 | 0.97207 | 0.92342
0.7 | 0.93016 | 0.98110 | 0.79739 | 0.97316 | 0.92045 | 0.92886 | 0.98052 | 0.80529 | 0.96856 | 0.92081
0.8 | 0.93016 | 0.98110 | 0.78624 | 0.97103 | 0.91713 | 0.92886 | 0.98052 | 0.78861 | 0.96327 | 0.91532
0.9 | 0.93016 | 0.98110 | 0.75857 | 0.96464 | 0.90862 | 0.92886 | 0.98052 | 0.75722 | 0.95316 | 0.90494
******** Validation loss improved from 0.02597581 to 0.02520458 ********

Epoch: 28/100 |  time : 09/17/19-17:06:59
=================================================================
train_loss: 0.02348374, train_bce_loss: 0.01336577, train_dice_loss: 0.08677648, train_vae_loss: 0.04113477
valid_loss: 0.02431261, valid_bce_loss: 0.01489459, valid_dice_loss: 0.08154403, valid_vae_loss: 0.04242536
0.1 | 0.93106 | 0.98150 | 0.79863 | 0.97391 | 0.92127 | 0.92886 | 0.98052 | 0.80888 | 0.97853 | 0.92420
0.2 | 0.93106 | 0.98150 | 0.81314 | 0.97654 | 0.92556 | 0.92886 | 0.98052 | 0.82425 | 0.97917 | 0.92820
0.3 | 0.93106 | 0.98150 | 0.81818 | 0.97750 | 0.92706 | 0.92886 | 0.98052 | 0.82925 | 0.97899 | 0.92940
0.4 | 0.93106 | 0.98150 | 0.81991 | 0.97813 | 0.92765 | 0.92886 | 0.98052 | 0.83021 | 0.97832 | 0.92948
0.5 | 0.93106 | 0.98150 | 0.81945 | 0.97802 | 0.92751 | 0.92886 | 0.98052 | 0.82896 | 0.97729 | 0.92891
0.6 | 0.93106 | 0.98150 | 0.81704 | 0.97782 | 0.92685 | 0.92886 | 0.98052 | 0.82656 | 0.97584 | 0.92795
0.7 | 0.93106 | 0.98150 | 0.81177 | 0.97677 | 0.92527 | 0.92886 | 0.98052 | 0.82103 | 0.97354 | 0.92599
0.8 | 0.93106 | 0.98150 | 0.80187 | 0.97400 | 0.92211 | 0.92886 | 0.98052 | 0.80789 | 0.96941 | 0.92167
0.9 | 0.93106 | 0.98150 | 0.77447 | 0.96739 | 0.91360 | 0.92886 | 0.98052 | 0.77735 | 0.96091 | 0.91191
******** Validation loss improved from 0.02520458 to 0.02431261 ********

Epoch: 29/100 |  time : 09/17/19-17:53:33
=================================================================
train_loss: 0.02286353, train_bce_loss: 0.01267280, train_dice_loss: 0.08645692, train_vae_loss: 0.04079596
valid_loss: 0.02381345, valid_bce_loss: 0.01450828, valid_dice_loss: 0.08150366, valid_vae_loss: 0.04056464
0.1 | 0.92987 | 0.98110 | 0.80046 | 0.97513 | 0.92164 | 0.92886 | 0.98052 | 0.80818 | 0.97671 | 0.92357
0.2 | 0.92986 | 0.98110 | 0.81603 | 0.97745 | 0.92611 | 0.92886 | 0.98052 | 0.82252 | 0.97866 | 0.92764
0.3 | 0.92986 | 0.98110 | 0.82116 | 0.97849 | 0.92765 | 0.92886 | 0.98052 | 0.82728 | 0.97962 | 0.92907
0.4 | 0.92986 | 0.98110 | 0.82297 | 0.97891 | 0.92821 | 0.92886 | 0.98052 | 0.82765 | 0.97968 | 0.92918
0.5 | 0.92986 | 0.98110 | 0.82296 | 0.97901 | 0.92823 | 0.92886 | 0.98052 | 0.82561 | 0.97933 | 0.92858
0.6 | 0.92986 | 0.98110 | 0.82011 | 0.97837 | 0.92736 | 0.92886 | 0.98052 | 0.82263 | 0.97854 | 0.92764
0.7 | 0.92986 | 0.98110 | 0.81567 | 0.97710 | 0.92593 | 0.92886 | 0.98052 | 0.81504 | 0.97711 | 0.92538
0.8 | 0.92986 | 0.98110 | 0.80544 | 0.97472 | 0.92278 | 0.92886 | 0.98052 | 0.80302 | 0.97417 | 0.92164
0.9 | 0.92986 | 0.98110 | 0.77928 | 0.96844 | 0.91467 | 0.92886 | 0.98052 | 0.77435 | 0.96762 | 0.91284
******** Validation loss improved from 0.02431261 to 0.02381345 ********

Epoch: 30/100 |  time : 09/17/19-18:40:12
=================================================================
train_loss: 0.02220791, train_bce_loss: 0.01233663, train_dice_loss: 0.08231536, train_vae_loss: 0.04107069
valid_loss: 0.02422114, valid_bce_loss: 0.01470175, valid_dice_loss: 0.08173873, valid_vae_loss: 0.04285863
0.1 | 0.93361 | 0.98150 | 0.81057 | 0.97513 | 0.92520 | 0.94341 | 0.98052 | 0.80094 | 0.97598 | 0.92521
0.2 | 0.93073 | 0.98150 | 0.82456 | 0.97785 | 0.92866 | 0.92886 | 0.98052 | 0.81779 | 0.97660 | 0.92594
0.3 | 0.93066 | 0.98150 | 0.82984 | 0.97931 | 0.93033 | 0.92886 | 0.98052 | 0.82489 | 0.97651 | 0.92770
0.4 | 0.93066 | 0.98150 | 0.83163 | 0.97978 | 0.93089 | 0.92886 | 0.98052 | 0.82734 | 0.97597 | 0.92817
0.5 | 0.93066 | 0.98150 | 0.83059 | 0.97993 | 0.93067 | 0.92886 | 0.98052 | 0.82682 | 0.97501 | 0.92780
0.6 | 0.93066 | 0.98150 | 0.82785 | 0.97963 | 0.92991 | 0.92886 | 0.98052 | 0.82328 | 0.97366 | 0.92658
0.7 | 0.93066 | 0.98150 | 0.82255 | 0.97877 | 0.92837 | 0.92886 | 0.98052 | 0.81793 | 0.97147 | 0.92470
0.8 | 0.93066 | 0.98150 | 0.81255 | 0.97627 | 0.92524 | 0.92886 | 0.98052 | 0.80959 | 0.96765 | 0.92165
0.9 | 0.93066 | 0.98150 | 0.78630 | 0.96925 | 0.91693 | 0.92886 | 0.98052 | 0.78705 | 0.95978 | 0.91405

Epoch: 31/100 |  time : 09/17/19-19:27:02
=================================================================
train_loss: 0.02251335, train_bce_loss: 0.01266386, train_dice_loss: 0.08260450, train_vae_loss: 0.04121808
valid_loss: 0.02376139, valid_bce_loss: 0.01462264, valid_dice_loss: 0.07956149, valid_vae_loss: 0.04107131
0.1 | 0.94365 | 0.98130 | 0.80690 | 0.97536 | 0.92680 | 0.94333 | 0.98052 | 0.80347 | 0.97746 | 0.92620
0.2 | 0.93997 | 0.98130 | 0.82095 | 0.97813 | 0.93009 | 0.94556 | 0.98052 | 0.82009 | 0.97778 | 0.93099
0.3 | 0.93596 | 0.98130 | 0.82598 | 0.97921 | 0.93061 | 0.94699 | 0.98052 | 0.82623 | 0.97713 | 0.93272
0.4 | 0.93393 | 0.98130 | 0.82750 | 0.97958 | 0.93058 | 0.94814 | 0.98052 | 0.82733 | 0.97596 | 0.93299
0.5 | 0.93256 | 0.98130 | 0.82703 | 0.97955 | 0.93011 | 0.94562 | 0.98052 | 0.82626 | 0.97434 | 0.93169
0.6 | 0.93065 | 0.98130 | 0.82467 | 0.97899 | 0.92890 | 0.94150 | 0.98052 | 0.82309 | 0.97206 | 0.92929
0.7 | 0.93025 | 0.98130 | 0.81951 | 0.97778 | 0.92721 | 0.93457 | 0.98052 | 0.81873 | 0.96867 | 0.92562
0.8 | 0.93016 | 0.98130 | 0.80915 | 0.97550 | 0.92403 | 0.93037 | 0.98052 | 0.80895 | 0.96348 | 0.92083
0.9 | 0.93016 | 0.98130 | 0.78386 | 0.96922 | 0.91613 | 0.92893 | 0.98052 | 0.78274 | 0.95423 | 0.91161
******** Validation loss improved from 0.02381345 to 0.02376139 ********

Epoch: 32/100 |  time : 09/17/19-20:14:02
=================================================================
train_loss: 0.02180202, train_bce_loss: 0.01202806, train_dice_loss: 0.08090412, train_vae_loss: 0.04089157
valid_loss: 0.02295186, valid_bce_loss: 0.01346250, valid_dice_loss: 0.07844054, valid_vae_loss: 0.04337801
0.1 | 0.94768 | 0.98110 | 0.80560 | 0.97638 | 0.92769 | 0.94858 | 0.98052 | 0.80488 | 0.97757 | 0.92789
0.2 | 0.94739 | 0.98110 | 0.81965 | 0.97892 | 0.93176 | 0.94937 | 0.98052 | 0.81739 | 0.97948 | 0.93169
0.3 | 0.94701 | 0.98110 | 0.82447 | 0.98003 | 0.93315 | 0.94956 | 0.98052 | 0.82247 | 0.98012 | 0.93317
0.4 | 0.94613 | 0.98110 | 0.82644 | 0.98032 | 0.93350 | 0.94948 | 0.98052 | 0.82381 | 0.97985 | 0.93342
0.5 | 0.94462 | 0.98110 | 0.82604 | 0.98020 | 0.93299 | 0.94923 | 0.98052 | 0.82206 | 0.97913 | 0.93274
0.6 | 0.94178 | 0.98110 | 0.82365 | 0.97967 | 0.93155 | 0.94911 | 0.98052 | 0.81870 | 0.97805 | 0.93159
0.7 | 0.93833 | 0.98110 | 0.81792 | 0.97874 | 0.92902 | 0.94779 | 0.98052 | 0.81310 | 0.97638 | 0.92945
0.8 | 0.93513 | 0.98110 | 0.80751 | 0.97635 | 0.92502 | 0.94492 | 0.98052 | 0.80473 | 0.97339 | 0.92589
0.9 | 0.93171 | 0.98110 | 0.78282 | 0.97013 | 0.91644 | 0.93784 | 0.98052 | 0.77873 | 0.96698 | 0.91602
******** Validation loss improved from 0.02376139 to 0.02295186 ********

Epoch: 33/100 |  time : 09/17/19-21:01:03
=================================================================
train_loss: 0.02161225, train_bce_loss: 0.01205219, train_dice_loss: 0.07870273, train_vae_loss: 0.04100225
valid_loss: 0.02240272, valid_bce_loss: 0.01318550, valid_dice_loss: 0.07731930, valid_vae_loss: 0.04122387
0.1 | 0.94831 | 0.98110 | 0.81114 | 0.97597 | 0.92913 | 0.95332 | 0.98052 | 0.80674 | 0.97816 | 0.92969
0.2 | 0.94768 | 0.98110 | 0.82563 | 0.97887 | 0.93332 | 0.95370 | 0.98052 | 0.82127 | 0.98003 | 0.93388
0.3 | 0.94741 | 0.98110 | 0.83131 | 0.97988 | 0.93492 | 0.95351 | 0.98052 | 0.82830 | 0.98077 | 0.93578
0.4 | 0.94708 | 0.98110 | 0.83338 | 0.98043 | 0.93550 | 0.95355 | 0.98052 | 0.82775 | 0.98097 | 0.93570
0.5 | 0.94642 | 0.98110 | 0.83323 | 0.98025 | 0.93525 | 0.95305 | 0.98052 | 0.82490 | 0.98077 | 0.93481
0.6 | 0.94561 | 0.98110 | 0.83004 | 0.98006 | 0.93420 | 0.95241 | 0.98052 | 0.81994 | 0.98053 | 0.93335
0.7 | 0.94408 | 0.98110 | 0.82500 | 0.97932 | 0.93237 | 0.95160 | 0.98052 | 0.81311 | 0.97942 | 0.93116
0.8 | 0.94119 | 0.98110 | 0.81491 | 0.97724 | 0.92861 | 0.94950 | 0.98052 | 0.79960 | 0.97721 | 0.92671
0.9 | 0.93583 | 0.98110 | 0.78894 | 0.97127 | 0.91929 | 0.94487 | 0.98052 | 0.76793 | 0.97215 | 0.91637
******** Validation loss improved from 0.02295186 to 0.02240272 ********

Epoch: 34/100 |  time : 09/17/19-21:48:02
=================================================================
train_loss: 0.02126463, train_bce_loss: 0.01182907, train_dice_loss: 0.07716215, train_vae_loss: 0.04085165
valid_loss: 0.02240422, valid_bce_loss: 0.01355850, valid_dice_loss: 0.07498432, valid_vae_loss: 0.04058988
0.1 | 0.94960 | 0.98140 | 0.81240 | 0.97712 | 0.93013 | 0.95131 | 0.98052 | 0.81392 | 0.97753 | 0.93082
0.2 | 0.94946 | 0.98140 | 0.82627 | 0.97972 | 0.93421 | 0.95162 | 0.98052 | 0.82864 | 0.97898 | 0.93494
0.3 | 0.94929 | 0.98140 | 0.83143 | 0.98092 | 0.93576 | 0.95177 | 0.98052 | 0.83323 | 0.97921 | 0.93618
0.4 | 0.94952 | 0.98140 | 0.83327 | 0.98113 | 0.93633 | 0.95180 | 0.98052 | 0.83358 | 0.97887 | 0.93619
0.5 | 0.94913 | 0.98140 | 0.83345 | 0.98103 | 0.93625 | 0.95172 | 0.98052 | 0.83171 | 0.97813 | 0.93552
0.6 | 0.94881 | 0.98140 | 0.83203 | 0.98042 | 0.93566 | 0.95148 | 0.98052 | 0.82723 | 0.97741 | 0.93416
0.7 | 0.94764 | 0.98140 | 0.82735 | 0.97935 | 0.93393 | 0.95113 | 0.98052 | 0.81764 | 0.97545 | 0.93119
0.8 | 0.94590 | 0.98140 | 0.81762 | 0.97695 | 0.93046 | 0.95007 | 0.98052 | 0.80287 | 0.97177 | 0.92631
0.9 | 0.94020 | 0.98140 | 0.79089 | 0.97082 | 0.92083 | 0.94765 | 0.98052 | 0.76947 | 0.96378 | 0.91536

Epoch: 35/100 |  time : 09/17/19-22:34:55
=================================================================
train_loss: 0.02119661, train_bce_loss: 0.01188042, train_dice_loss: 0.07560726, train_vae_loss: 0.04131544
valid_loss: 0.02268994, valid_bce_loss: 0.01426278, valid_dice_loss: 0.07216395, valid_vae_loss: 0.04063313
0.1 | 0.95029 | 0.98150 | 0.81566 | 0.97773 | 0.93129 | 0.95158 | 0.98052 | 0.82926 | 0.97941 | 0.93519
0.2 | 0.95039 | 0.98150 | 0.82994 | 0.98009 | 0.93548 | 0.95189 | 0.98052 | 0.83921 | 0.98068 | 0.93808
0.3 | 0.95007 | 0.98150 | 0.83521 | 0.98104 | 0.93696 | 0.95171 | 0.98052 | 0.84191 | 0.98074 | 0.93872
0.4 | 0.94997 | 0.98150 | 0.83720 | 0.98149 | 0.93754 | 0.95224 | 0.98052 | 0.84062 | 0.98029 | 0.93842
0.5 | 0.94932 | 0.98150 | 0.83610 | 0.98153 | 0.93711 | 0.95190 | 0.98052 | 0.83774 | 0.97939 | 0.93739
0.6 | 0.94910 | 0.98150 | 0.83359 | 0.98108 | 0.93632 | 0.95186 | 0.98052 | 0.83340 | 0.97828 | 0.93601
0.7 | 0.94821 | 0.98150 | 0.82773 | 0.98008 | 0.93438 | 0.95110 | 0.98052 | 0.82484 | 0.97605 | 0.93313
0.8 | 0.94651 | 0.98150 | 0.81727 | 0.97802 | 0.93082 | 0.95050 | 0.98052 | 0.80975 | 0.97255 | 0.92833
0.9 | 0.94248 | 0.98150 | 0.79127 | 0.97250 | 0.92194 | 0.94837 | 0.98052 | 0.77869 | 0.96528 | 0.91822

Epoch: 36/100 |  time : 09/17/19-23:21:51
=================================================================
train_loss: 0.02106532, train_bce_loss: 0.01168517, train_dice_loss: 0.07631036, train_vae_loss: 0.04086150
valid_loss: 0.02445834, valid_bce_loss: 0.01568177, valid_dice_loss: 0.07776913, valid_vae_loss: 0.04136008
0.1 | 0.95111 | 0.98179 | 0.81201 | 0.97682 | 0.93043 | 0.95345 | 0.98052 | 0.81749 | 0.97354 | 0.93125
0.2 | 0.95103 | 0.98179 | 0.82577 | 0.97935 | 0.93449 | 0.95230 | 0.98052 | 0.82865 | 0.97284 | 0.93358
0.3 | 0.95103 | 0.98179 | 0.83089 | 0.98029 | 0.93600 | 0.95138 | 0.98052 | 0.83180 | 0.97159 | 0.93383
0.4 | 0.95108 | 0.98179 | 0.83293 | 0.98055 | 0.93659 | 0.95060 | 0.98052 | 0.83054 | 0.96978 | 0.93286
0.5 | 0.95055 | 0.98179 | 0.83265 | 0.98052 | 0.93638 | 0.95023 | 0.98052 | 0.82800 | 0.96737 | 0.93153
0.6 | 0.95009 | 0.98179 | 0.83026 | 0.98007 | 0.93556 | 0.94980 | 0.98052 | 0.82256 | 0.96428 | 0.92929
0.7 | 0.94918 | 0.98179 | 0.82547 | 0.97916 | 0.93390 | 0.94874 | 0.98052 | 0.81454 | 0.96018 | 0.92600
0.8 | 0.94759 | 0.98179 | 0.81504 | 0.97692 | 0.93034 | 0.94754 | 0.98052 | 0.80122 | 0.95428 | 0.92089
0.9 | 0.94356 | 0.98179 | 0.78966 | 0.97067 | 0.92142 | 0.94431 | 0.98052 | 0.77418 | 0.94476 | 0.91094

Epoch: 37/100 |  time : 09/18/19-00:08:13
=================================================================
train_loss: 0.02096565, train_bce_loss: 0.01177227, train_dice_loss: 0.07457804, train_vae_loss: 0.04090032
valid_loss: 0.02245627, valid_bce_loss: 0.01345232, valid_dice_loss: 0.07488754, valid_vae_loss: 0.04205662
0.1 | 0.95242 | 0.98130 | 0.81681 | 0.97744 | 0.93199 | 0.95123 | 0.98052 | 0.81867 | 0.97792 | 0.93208
0.2 | 0.95293 | 0.98130 | 0.83039 | 0.97992 | 0.93613 | 0.95200 | 0.98052 | 0.83310 | 0.98058 | 0.93655
0.3 | 0.95273 | 0.98130 | 0.83514 | 0.98102 | 0.93755 | 0.95219 | 0.98052 | 0.83708 | 0.98114 | 0.93774
0.4 | 0.95241 | 0.98130 | 0.83717 | 0.98151 | 0.93810 | 0.95274 | 0.98052 | 0.83766 | 0.98148 | 0.93810
0.5 | 0.95217 | 0.98130 | 0.83687 | 0.98141 | 0.93794 | 0.95241 | 0.98052 | 0.83514 | 0.98108 | 0.93729
0.6 | 0.95163 | 0.98130 | 0.83458 | 0.98109 | 0.93715 | 0.95276 | 0.98052 | 0.83110 | 0.98034 | 0.93618
0.7 | 0.95076 | 0.98130 | 0.82912 | 0.97999 | 0.93529 | 0.95206 | 0.98052 | 0.82375 | 0.97895 | 0.93382
0.8 | 0.94861 | 0.98130 | 0.81862 | 0.97794 | 0.93161 | 0.95203 | 0.98052 | 0.80907 | 0.97601 | 0.92941
0.9 | 0.94475 | 0.98130 | 0.79222 | 0.97203 | 0.92257 | 0.95032 | 0.98052 | 0.78003 | 0.96956 | 0.92011

Epoch: 38/100 |  time : 09/18/19-00:54:10
=================================================================
train_loss: 0.02086428, train_bce_loss: 0.01158121, train_dice_loss: 0.07493438, train_vae_loss: 0.04105871
valid_loss: 0.02338849, valid_bce_loss: 0.01473472, valid_dice_loss: 0.07368710, valid_vae_loss: 0.04232001
0.1 | 0.95154 | 0.98160 | 0.81554 | 0.97793 | 0.93165 | 0.95044 | 0.98052 | 0.80945 | 0.98024 | 0.93016
0.2 | 0.95171 | 0.98160 | 0.82900 | 0.98063 | 0.93573 | 0.95002 | 0.98052 | 0.82645 | 0.98103 | 0.93451
0.3 | 0.95184 | 0.98160 | 0.83373 | 0.98180 | 0.93724 | 0.94911 | 0.98052 | 0.83272 | 0.98074 | 0.93577
0.4 | 0.95145 | 0.98160 | 0.83622 | 0.98217 | 0.93786 | 0.94831 | 0.98052 | 0.83464 | 0.97984 | 0.93583
0.5 | 0.95117 | 0.98160 | 0.83563 | 0.98206 | 0.93762 | 0.94753 | 0.98052 | 0.83421 | 0.97857 | 0.93521
0.6 | 0.95087 | 0.98160 | 0.83308 | 0.98168 | 0.93680 | 0.94668 | 0.98052 | 0.83258 | 0.97677 | 0.93414
0.7 | 0.95039 | 0.98160 | 0.82791 | 0.98075 | 0.93516 | 0.94563 | 0.98052 | 0.82822 | 0.97384 | 0.93205
0.8 | 0.94958 | 0.98160 | 0.81789 | 0.97854 | 0.93190 | 0.94461 | 0.98052 | 0.81593 | 0.96920 | 0.92756
0.9 | 0.94623 | 0.98160 | 0.79224 | 0.97249 | 0.92314 | 0.94182 | 0.98052 | 0.78783 | 0.96056 | 0.91768

Epoch: 39/100 |  time : 09/18/19-01:40:28
=================================================================
train_loss: 0.02087584, train_bce_loss: 0.01159632, train_dice_loss: 0.07503256, train_vae_loss: 0.04095527
valid_loss: 0.02216865, valid_bce_loss: 0.01335420, valid_dice_loss: 0.07348827, valid_vae_loss: 0.04136466
0.1 | 0.95137 | 0.98100 | 0.81580 | 0.97710 | 0.93132 | 0.95326 | 0.98052 | 0.80961 | 0.97929 | 0.93067
0.2 | 0.95148 | 0.98100 | 0.82954 | 0.97952 | 0.93539 | 0.95393 | 0.98052 | 0.82528 | 0.98063 | 0.93509
0.3 | 0.95162 | 0.98100 | 0.83513 | 0.98053 | 0.93707 | 0.95445 | 0.98052 | 0.83196 | 0.98148 | 0.93710
0.4 | 0.95156 | 0.98100 | 0.83716 | 0.98082 | 0.93764 | 0.95440 | 0.98052 | 0.83515 | 0.98134 | 0.93785
0.5 | 0.95128 | 0.98100 | 0.83648 | 0.98067 | 0.93736 | 0.95506 | 0.98052 | 0.83574 | 0.98032 | 0.93791
0.6 | 0.95082 | 0.98100 | 0.83408 | 0.98023 | 0.93653 | 0.95523 | 0.98052 | 0.83407 | 0.97871 | 0.93713
0.7 | 0.95056 | 0.98100 | 0.82894 | 0.97928 | 0.93495 | 0.95480 | 0.98052 | 0.82987 | 0.97614 | 0.93534
0.8 | 0.94992 | 0.98100 | 0.81871 | 0.97713 | 0.93169 | 0.95402 | 0.98052 | 0.81793 | 0.97241 | 0.93122
0.9 | 0.94670 | 0.98100 | 0.79375 | 0.97165 | 0.92327 | 0.95175 | 0.98052 | 0.79122 | 0.96505 | 0.92213
******** Validation loss improved from 0.02240272 to 0.02216865 ********

Epoch: 40/100 |  time : 09/18/19-02:26:36
=================================================================
train_loss: 0.02084312, train_bce_loss: 0.01156891, train_dice_loss: 0.07452845, train_vae_loss: 0.04135143
valid_loss: 0.02242440, valid_bce_loss: 0.01379223, valid_dice_loss: 0.07293032, valid_vae_loss: 0.04097582
0.1 | 0.95325 | 0.98130 | 0.81380 | 0.97849 | 0.93171 | 0.95275 | 0.98052 | 0.81977 | 0.97990 | 0.93324
0.2 | 0.95331 | 0.98130 | 0.82810 | 0.98082 | 0.93588 | 0.95264 | 0.98052 | 0.83301 | 0.98107 | 0.93681
0.3 | 0.95317 | 0.98130 | 0.83366 | 0.98194 | 0.93752 | 0.95269 | 0.98052 | 0.83653 | 0.98130 | 0.93776
0.4 | 0.95295 | 0.98130 | 0.83535 | 0.98231 | 0.93798 | 0.95358 | 0.98052 | 0.83730 | 0.98090 | 0.93808
0.5 | 0.95251 | 0.98130 | 0.83449 | 0.98222 | 0.93763 | 0.95359 | 0.98052 | 0.83430 | 0.98020 | 0.93715
0.6 | 0.95216 | 0.98130 | 0.83190 | 0.98158 | 0.93673 | 0.95313 | 0.98052 | 0.83022 | 0.97906 | 0.93573
0.7 | 0.95155 | 0.98130 | 0.82700 | 0.98065 | 0.93513 | 0.95204 | 0.98052 | 0.82407 | 0.97726 | 0.93347
0.8 | 0.95050 | 0.98130 | 0.81650 | 0.97816 | 0.93161 | 0.95032 | 0.98052 | 0.81106 | 0.97398 | 0.92897
0.9 | 0.94743 | 0.98130 | 0.78971 | 0.97185 | 0.92257 | 0.94764 | 0.98052 | 0.78404 | 0.96746 | 0.91992

Epoch: 41/100 |  time : 09/18/19-03:12:38
=================================================================
train_loss: 0.02060374, train_bce_loss: 0.01149037, train_dice_loss: 0.07303452, train_vae_loss: 0.04107990
valid_loss: 0.02362395, valid_bce_loss: 0.01516632, valid_dice_loss: 0.07224738, valid_vae_loss: 0.04266157
0.1 | 0.95403 | 0.98130 | 0.81890 | 0.97791 | 0.93303 | 0.95379 | 0.98052 | 0.82952 | 0.98064 | 0.93612
0.2 | 0.95463 | 0.98130 | 0.83244 | 0.98057 | 0.93723 | 0.95276 | 0.98052 | 0.83698 | 0.98179 | 0.93801
0.3 | 0.95460 | 0.98130 | 0.83745 | 0.98161 | 0.93874 | 0.95188 | 0.98052 | 0.83730 | 0.98199 | 0.93792
0.4 | 0.95457 | 0.98130 | 0.83945 | 0.98199 | 0.93933 | 0.95106 | 0.98052 | 0.83425 | 0.98111 | 0.93674
0.5 | 0.95429 | 0.98130 | 0.83860 | 0.98193 | 0.93903 | 0.95058 | 0.98052 | 0.83081 | 0.97966 | 0.93539
0.6 | 0.95396 | 0.98130 | 0.83611 | 0.98156 | 0.93823 | 0.94968 | 0.98052 | 0.82581 | 0.97750 | 0.93338
0.7 | 0.95353 | 0.98130 | 0.83125 | 0.98051 | 0.93665 | 0.94893 | 0.98052 | 0.81698 | 0.97407 | 0.93013
0.8 | 0.95255 | 0.98130 | 0.82125 | 0.97854 | 0.93341 | 0.94728 | 0.98052 | 0.80284 | 0.96855 | 0.92480
0.9 | 0.94938 | 0.98130 | 0.79588 | 0.97285 | 0.92485 | 0.94458 | 0.98052 | 0.77391 | 0.95912 | 0.91453

Epoch: 42/100 |  time : 09/18/19-03:58:59
=================================================================
train_loss: 0.02034186, train_bce_loss: 0.01128208, train_dice_loss: 0.07210283, train_vae_loss: 0.04105917
valid_loss: 0.02280609, valid_bce_loss: 0.01457942, valid_dice_loss: 0.07049742, valid_vae_loss: 0.04092814
0.1 | 0.95467 | 0.98140 | 0.82072 | 0.97780 | 0.93365 | 0.95512 | 0.98052 | 0.82221 | 0.97754 | 0.93385
0.2 | 0.95508 | 0.98140 | 0.83460 | 0.98024 | 0.93783 | 0.95541 | 0.98052 | 0.83441 | 0.97851 | 0.93722
0.3 | 0.95508 | 0.98140 | 0.83945 | 0.98131 | 0.93931 | 0.95555 | 0.98052 | 0.83876 | 0.97873 | 0.93839
0.4 | 0.95489 | 0.98140 | 0.84133 | 0.98181 | 0.93986 | 0.95525 | 0.98052 | 0.83920 | 0.97851 | 0.93837
0.5 | 0.95474 | 0.98140 | 0.84104 | 0.98176 | 0.93973 | 0.95485 | 0.98052 | 0.83769 | 0.97794 | 0.93775
0.6 | 0.95436 | 0.98140 | 0.83841 | 0.98132 | 0.93887 | 0.95436 | 0.98052 | 0.83434 | 0.97692 | 0.93654
0.7 | 0.95369 | 0.98140 | 0.83358 | 0.98005 | 0.93718 | 0.95371 | 0.98052 | 0.82786 | 0.97532 | 0.93435
0.8 | 0.95234 | 0.98140 | 0.82296 | 0.97770 | 0.93360 | 0.95316 | 0.98052 | 0.81626 | 0.97234 | 0.93057
0.9 | 0.94885 | 0.98140 | 0.79855 | 0.97207 | 0.92522 | 0.95159 | 0.98052 | 0.79091 | 0.96577 | 0.92220

Epoch: 43/100 |  time : 09/18/19-04:45:19
=================================================================
train_loss: 0.02023856, train_bce_loss: 0.01117215, train_dice_loss: 0.07209898, train_vae_loss: 0.04090945
valid_loss: 0.02227282, valid_bce_loss: 0.01403207, valid_dice_loss: 0.07091389, valid_vae_loss: 0.03955767
0.1 | 0.95547 | 0.98100 | 0.81914 | 0.97835 | 0.93349 | 0.95472 | 0.98052 | 0.82383 | 0.97837 | 0.93436
0.2 | 0.95602 | 0.98100 | 0.83346 | 0.98062 | 0.93777 | 0.95465 | 0.98052 | 0.83589 | 0.97962 | 0.93767
0.3 | 0.95595 | 0.98100 | 0.83875 | 0.98160 | 0.93932 | 0.95440 | 0.98052 | 0.83876 | 0.97973 | 0.93835
0.4 | 0.95582 | 0.98100 | 0.84008 | 0.98186 | 0.93969 | 0.95447 | 0.98052 | 0.83789 | 0.97928 | 0.93804
0.5 | 0.95556 | 0.98100 | 0.83960 | 0.98185 | 0.93950 | 0.95409 | 0.98052 | 0.83601 | 0.97838 | 0.93725
0.6 | 0.95523 | 0.98100 | 0.83720 | 0.98165 | 0.93877 | 0.95362 | 0.98052 | 0.83236 | 0.97694 | 0.93586
0.7 | 0.95444 | 0.98100 | 0.83197 | 0.98080 | 0.93705 | 0.95338 | 0.98052 | 0.82529 | 0.97492 | 0.93353
0.8 | 0.95318 | 0.98100 | 0.82101 | 0.97862 | 0.93346 | 0.95310 | 0.98052 | 0.81127 | 0.97149 | 0.92910
0.9 | 0.95011 | 0.98100 | 0.79555 | 0.97299 | 0.92491 | 0.95146 | 0.98052 | 0.78402 | 0.96451 | 0.92013

Epoch: 44/100 |  time : 09/18/19-05:31:38
=================================================================
train_loss: 0.02016993, train_bce_loss: 0.01106517, train_dice_loss: 0.07213609, train_vae_loss: 0.04104179
valid_loss: 0.02244665, valid_bce_loss: 0.01391426, valid_dice_loss: 0.07217777, valid_vae_loss: 0.04097465
0.1 | 0.95589 | 0.98170 | 0.81886 | 0.97744 | 0.93347 | 0.95492 | 0.98052 | 0.81939 | 0.98054 | 0.93385
0.2 | 0.95616 | 0.98170 | 0.83220 | 0.98010 | 0.93754 | 0.95488 | 0.98052 | 0.83211 | 0.98179 | 0.93733
0.3 | 0.95605 | 0.98170 | 0.83747 | 0.98100 | 0.93905 | 0.95467 | 0.98052 | 0.83639 | 0.98184 | 0.93836
0.4 | 0.95616 | 0.98170 | 0.83928 | 0.98133 | 0.93962 | 0.95433 | 0.98052 | 0.83624 | 0.98130 | 0.93810
0.5 | 0.95609 | 0.98170 | 0.83876 | 0.98127 | 0.93945 | 0.95390 | 0.98052 | 0.83449 | 0.98032 | 0.93731
0.6 | 0.95582 | 0.98170 | 0.83551 | 0.98083 | 0.93847 | 0.95334 | 0.98052 | 0.83109 | 0.97890 | 0.93597
0.7 | 0.95510 | 0.98170 | 0.83093 | 0.97994 | 0.93692 | 0.95266 | 0.98052 | 0.82458 | 0.97675 | 0.93363
0.8 | 0.95434 | 0.98170 | 0.82188 | 0.97816 | 0.93402 | 0.95195 | 0.98052 | 0.81024 | 0.97305 | 0.92894
0.9 | 0.95159 | 0.98170 | 0.79814 | 0.97282 | 0.92606 | 0.94906 | 0.98052 | 0.77815 | 0.96562 | 0.91834

Epoch: 45/100 |  time : 09/18/19-06:17:58
=================================================================
train_loss: 0.02039122, train_bce_loss: 0.01129900, train_dice_loss: 0.07235169, train_vae_loss: 0.04116846
valid_loss: 0.02329897, valid_bce_loss: 0.01470628, valid_dice_loss: 0.07418080, valid_vae_loss: 0.04115867
0.1 | 0.95435 | 0.98160 | 0.81827 | 0.97918 | 0.93335 | 0.95584 | 0.98052 | 0.82512 | 0.98026 | 0.93544
0.2 | 0.95449 | 0.98160 | 0.83273 | 0.98180 | 0.93765 | 0.95498 | 0.98052 | 0.83375 | 0.98129 | 0.93763
0.3 | 0.95452 | 0.98160 | 0.83822 | 0.98264 | 0.93924 | 0.95422 | 0.98052 | 0.83525 | 0.98071 | 0.93767
0.4 | 0.95438 | 0.98160 | 0.83963 | 0.98284 | 0.93961 | 0.95352 | 0.98052 | 0.83267 | 0.97949 | 0.93655
0.5 | 0.95422 | 0.98160 | 0.83884 | 0.98273 | 0.93935 | 0.95279 | 0.98052 | 0.82880 | 0.97763 | 0.93494
0.6 | 0.95379 | 0.98160 | 0.83606 | 0.98214 | 0.93840 | 0.95238 | 0.98052 | 0.82366 | 0.97487 | 0.93286
0.7 | 0.95344 | 0.98160 | 0.83107 | 0.98110 | 0.93680 | 0.95135 | 0.98052 | 0.81430 | 0.97083 | 0.92925
0.8 | 0.95234 | 0.98160 | 0.82083 | 0.97889 | 0.93341 | 0.95034 | 0.98052 | 0.79617 | 0.96474 | 0.92294
0.9 | 0.94946 | 0.98160 | 0.79532 | 0.97293 | 0.92483 | 0.94778 | 0.98052 | 0.76756 | 0.95522 | 0.91277

Epoch: 46/100 |  time : 09/18/19-07:04:17
=================================================================
train_loss: 0.02031776, train_bce_loss: 0.01114630, train_dice_loss: 0.07294762, train_vae_loss: 0.04105955
valid_loss: 0.02462279, valid_bce_loss: 0.01530621, valid_dice_loss: 0.08261606, valid_vae_loss: 0.04116219
0.1 | 0.95386 | 0.98100 | 0.81915 | 0.97749 | 0.93287 | 0.95453 | 0.98052 | 0.79048 | 0.96660 | 0.92303
0.2 | 0.95430 | 0.98100 | 0.83303 | 0.97989 | 0.93706 | 0.95522 | 0.98052 | 0.80945 | 0.96499 | 0.92755
0.3 | 0.95468 | 0.98100 | 0.83792 | 0.98077 | 0.93859 | 0.95534 | 0.98052 | 0.81839 | 0.96329 | 0.92938
0.4 | 0.95462 | 0.98100 | 0.83951 | 0.98096 | 0.93902 | 0.95537 | 0.98052 | 0.82316 | 0.96125 | 0.93008
0.5 | 0.95454 | 0.98100 | 0.83866 | 0.98107 | 0.93882 | 0.95494 | 0.98052 | 0.82284 | 0.95884 | 0.92929
0.6 | 0.95432 | 0.98100 | 0.83673 | 0.98072 | 0.93819 | 0.95437 | 0.98052 | 0.82068 | 0.95593 | 0.92788
0.7 | 0.95370 | 0.98100 | 0.83221 | 0.97972 | 0.93666 | 0.95483 | 0.98052 | 0.81715 | 0.95229 | 0.92620
0.8 | 0.95286 | 0.98100 | 0.82224 | 0.97752 | 0.93340 | 0.95457 | 0.98052 | 0.80623 | 0.94729 | 0.92215
0.9 | 0.95069 | 0.98100 | 0.79875 | 0.97222 | 0.92567 | 0.95297 | 0.98052 | 0.78603 | 0.94087 | 0.91510

Epoch: 47/100 |  time : 09/18/19-07:50:36
=================================================================
train_loss: 0.01994268, train_bce_loss: 0.01092741, train_dice_loss: 0.07105663, train_vae_loss: 0.04095092
valid_loss: 0.02363146, valid_bce_loss: 0.01487113, valid_dice_loss: 0.07632124, valid_vae_loss: 0.04102433
0.1 | 0.95603 | 0.98110 | 0.82110 | 0.97870 | 0.93423 | 0.95211 | 0.98052 | 0.81115 | 0.97450 | 0.92957
0.2 | 0.95688 | 0.98110 | 0.83522 | 0.98120 | 0.93860 | 0.95100 | 0.98052 | 0.82865 | 0.97400 | 0.93354
0.3 | 0.95698 | 0.98110 | 0.84010 | 0.98209 | 0.94007 | 0.94996 | 0.98052 | 0.83516 | 0.97282 | 0.93462
0.4 | 0.95688 | 0.98110 | 0.84196 | 0.98238 | 0.94058 | 0.94909 | 0.98052 | 0.83741 | 0.97090 | 0.93448
0.5 | 0.95695 | 0.98110 | 0.84195 | 0.98227 | 0.94057 | 0.94862 | 0.98052 | 0.83571 | 0.96815 | 0.93325
0.6 | 0.95662 | 0.98110 | 0.84005 | 0.98186 | 0.93990 | 0.94776 | 0.98052 | 0.83147 | 0.96451 | 0.93107
0.7 | 0.95591 | 0.98110 | 0.83519 | 0.98077 | 0.93825 | 0.94674 | 0.98052 | 0.82356 | 0.95971 | 0.92764
0.8 | 0.95489 | 0.98110 | 0.82450 | 0.97871 | 0.93480 | 0.94543 | 0.98052 | 0.80853 | 0.95344 | 0.92198
0.9 | 0.95227 | 0.98110 | 0.80031 | 0.97315 | 0.92671 | 0.94385 | 0.98052 | 0.77996 | 0.94416 | 0.91212

Epoch: 48/100 |  time : 09/18/19-08:37:03
=================================================================
train_loss: 0.02002192, train_bce_loss: 0.01100815, train_dice_loss: 0.07127996, train_vae_loss: 0.04087407
valid_loss: 0.02266131, valid_bce_loss: 0.01416637, valid_dice_loss: 0.07343618, valid_vae_loss: 0.03984598
0.1 | 0.95340 | 0.98199 | 0.82309 | 0.97745 | 0.93398 | 0.95713 | 0.98052 | 0.81564 | 0.97908 | 0.93309
0.2 | 0.95406 | 0.98199 | 0.83736 | 0.98000 | 0.93835 | 0.95804 | 0.98052 | 0.82997 | 0.97863 | 0.93679
0.3 | 0.95418 | 0.98199 | 0.84238 | 0.98095 | 0.93988 | 0.95798 | 0.98052 | 0.83386 | 0.97730 | 0.93741
0.4 | 0.95447 | 0.98199 | 0.84383 | 0.98125 | 0.94039 | 0.95779 | 0.98052 | 0.83323 | 0.97535 | 0.93672
0.5 | 0.95435 | 0.98199 | 0.84278 | 0.98119 | 0.94008 | 0.95753 | 0.98052 | 0.83152 | 0.97284 | 0.93560
0.6 | 0.95424 | 0.98199 | 0.84065 | 0.98083 | 0.93943 | 0.95714 | 0.98052 | 0.82816 | 0.96964 | 0.93387
0.7 | 0.95398 | 0.98199 | 0.83588 | 0.98000 | 0.93796 | 0.95698 | 0.98052 | 0.82202 | 0.96572 | 0.93131
0.8 | 0.95296 | 0.98199 | 0.82582 | 0.97774 | 0.93463 | 0.95614 | 0.98052 | 0.81020 | 0.96037 | 0.92681
0.9 | 0.95151 | 0.98199 | 0.80032 | 0.97180 | 0.92641 | 0.95462 | 0.98052 | 0.78539 | 0.95090 | 0.91786

Epoch: 49/100 |  time : 09/18/19-09:23:37
=================================================================
train_loss: 0.01972204, train_bce_loss: 0.01071880, train_dice_loss: 0.07055629, train_vae_loss: 0.04091372
valid_loss: 0.02219913, valid_bce_loss: 0.01356128, valid_dice_loss: 0.07285467, valid_vae_loss: 0.04064645
0.1 | 0.95555 | 0.98160 | 0.82197 | 0.97869 | 0.93445 | 0.95776 | 0.98052 | 0.82012 | 0.97917 | 0.93439
0.2 | 0.95600 | 0.98160 | 0.83562 | 0.98109 | 0.93858 | 0.95745 | 0.98052 | 0.83199 | 0.97993 | 0.93747
0.3 | 0.95617 | 0.98160 | 0.84049 | 0.98192 | 0.94004 | 0.95685 | 0.98052 | 0.83587 | 0.97992 | 0.93829
0.4 | 0.95646 | 0.98160 | 0.84200 | 0.98225 | 0.94058 | 0.95666 | 0.98052 | 0.83436 | 0.97932 | 0.93771
0.5 | 0.95634 | 0.98160 | 0.84150 | 0.98220 | 0.94041 | 0.95603 | 0.98052 | 0.83105 | 0.97833 | 0.93649
0.6 | 0.95590 | 0.98160 | 0.83914 | 0.98189 | 0.93963 | 0.95528 | 0.98052 | 0.82836 | 0.97689 | 0.93527
0.7 | 0.95556 | 0.98160 | 0.83420 | 0.98094 | 0.93808 | 0.95468 | 0.98052 | 0.82071 | 0.97462 | 0.93263
0.8 | 0.95484 | 0.98160 | 0.82473 | 0.97893 | 0.93502 | 0.95337 | 0.98052 | 0.80537 | 0.97095 | 0.92755
0.9 | 0.95230 | 0.98160 | 0.79899 | 0.97354 | 0.92661 | 0.95099 | 0.98052 | 0.77355 | 0.96324 | 0.91708

Epoch: 50/100 |  time : 09/18/19-10:10:32
=================================================================
train_loss: 0.01970617, train_bce_loss: 0.01069758, train_dice_loss: 0.07034173, train_vae_loss: 0.04113930
valid_loss: 0.02407698, valid_bce_loss: 0.01554780, valid_dice_loss: 0.07637636, valid_vae_loss: 0.04001107
0.1 | 0.95663 | 0.98110 | 0.82166 | 0.97893 | 0.93458 | 0.95352 | 0.98052 | 0.81753 | 0.97111 | 0.93067
0.2 | 0.95704 | 0.98110 | 0.83604 | 0.98154 | 0.93893 | 0.95261 | 0.98052 | 0.83268 | 0.96982 | 0.93391
0.3 | 0.95719 | 0.98110 | 0.84143 | 0.98253 | 0.94056 | 0.95213 | 0.98052 | 0.83894 | 0.96816 | 0.93494
0.4 | 0.95732 | 0.98110 | 0.84356 | 0.98284 | 0.94121 | 0.95100 | 0.98052 | 0.83989 | 0.96603 | 0.93436
0.5 | 0.95710 | 0.98110 | 0.84321 | 0.98304 | 0.94111 | 0.94991 | 0.98052 | 0.83757 | 0.96342 | 0.93286
0.6 | 0.95663 | 0.98110 | 0.84094 | 0.98250 | 0.94029 | 0.94876 | 0.98052 | 0.83402 | 0.96019 | 0.93087
0.7 | 0.95610 | 0.98110 | 0.83628 | 0.98157 | 0.93876 | 0.94819 | 0.98052 | 0.82602 | 0.95604 | 0.92769
0.8 | 0.95506 | 0.98110 | 0.82673 | 0.97945 | 0.93558 | 0.94723 | 0.98052 | 0.81277 | 0.95043 | 0.92274
0.9 | 0.95254 | 0.98110 | 0.80124 | 0.97384 | 0.92718 | 0.94486 | 0.98052 | 0.78286 | 0.94243 | 0.91267
Epoch    49: reducing learning rate of group 0 to 1.0000e-04.

Epoch: 51/100 |  time : 09/18/19-10:57:27
=================================================================
train_loss: 0.01915458, train_bce_loss: 0.01034327, train_dice_loss: 0.06784482, train_vae_loss: 0.04095479
valid_loss: 0.02477723, valid_bce_loss: 0.01650132, valid_dice_loss: 0.07510610, valid_vae_loss: 0.04065563
0.1 | 0.95770 | 0.98120 | 0.82818 | 0.98045 | 0.93688 | 0.95877 | 0.98052 | 0.82380 | 0.96571 | 0.93220
0.2 | 0.95819 | 0.98120 | 0.84234 | 0.98262 | 0.94108 | 0.95789 | 0.98052 | 0.83643 | 0.96397 | 0.93470
0.3 | 0.95859 | 0.98120 | 0.84752 | 0.98343 | 0.94269 | 0.95717 | 0.98052 | 0.83952 | 0.96202 | 0.93481
0.4 | 0.95876 | 0.98120 | 0.84938 | 0.98377 | 0.94328 | 0.95651 | 0.98052 | 0.83934 | 0.95972 | 0.93402
0.5 | 0.95883 | 0.98120 | 0.84902 | 0.98372 | 0.94319 | 0.95585 | 0.98052 | 0.83767 | 0.95703 | 0.93277
0.6 | 0.95840 | 0.98120 | 0.84655 | 0.98326 | 0.94235 | 0.95506 | 0.98052 | 0.83469 | 0.95386 | 0.93103
0.7 | 0.95799 | 0.98120 | 0.84109 | 0.98216 | 0.94061 | 0.95530 | 0.98052 | 0.82750 | 0.94972 | 0.92826
0.8 | 0.95710 | 0.98120 | 0.82960 | 0.98009 | 0.93700 | 0.95392 | 0.98052 | 0.81605 | 0.94459 | 0.92377
0.9 | 0.95466 | 0.98120 | 0.80211 | 0.97422 | 0.92805 | 0.95124 | 0.98052 | 0.78826 | 0.93900 | 0.91475

Epoch: 52/100 |  time : 09/18/19-11:44:23
=================================================================
train_loss: 0.01926298, train_bce_loss: 0.01045865, train_dice_loss: 0.06790979, train_vae_loss: 0.04105084
valid_loss: 0.02211388, valid_bce_loss: 0.01378281, valid_dice_loss: 0.07027959, valid_vae_loss: 0.04059667
0.1 | 0.95689 | 0.98110 | 0.82872 | 0.97997 | 0.93667 | 0.95794 | 0.98052 | 0.82441 | 0.97932 | 0.93555
0.2 | 0.95740 | 0.98110 | 0.84267 | 0.98230 | 0.94087 | 0.95708 | 0.98052 | 0.83794 | 0.98009 | 0.93891
0.3 | 0.95806 | 0.98110 | 0.84797 | 0.98313 | 0.94257 | 0.95726 | 0.98052 | 0.84262 | 0.97995 | 0.94009
0.4 | 0.95810 | 0.98110 | 0.84978 | 0.98345 | 0.94311 | 0.95632 | 0.98052 | 0.84399 | 0.97925 | 0.94002
0.5 | 0.95804 | 0.98110 | 0.84942 | 0.98344 | 0.94300 | 0.95536 | 0.98052 | 0.84218 | 0.97810 | 0.93904
0.6 | 0.95783 | 0.98110 | 0.84670 | 0.98284 | 0.94212 | 0.95428 | 0.98052 | 0.83891 | 0.97638 | 0.93752
0.7 | 0.95730 | 0.98110 | 0.84124 | 0.98169 | 0.94033 | 0.95300 | 0.98052 | 0.83332 | 0.97381 | 0.93516
0.8 | 0.95674 | 0.98110 | 0.83189 | 0.97941 | 0.93728 | 0.95131 | 0.98052 | 0.82263 | 0.96987 | 0.93108
0.9 | 0.95388 | 0.98110 | 0.80774 | 0.97357 | 0.92907 | 0.94836 | 0.98052 | 0.79361 | 0.96224 | 0.92118
******** Validation loss improved from 0.02216865 to 0.02211388 ********

Epoch: 53/100 |  time : 09/18/19-12:31:26
=================================================================
