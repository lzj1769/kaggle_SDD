Train on 2514 mini-batches, validate on 629 mini-batches
Epoch: 1/200 |  time : 09/05/19-18:35:07
=================================================================
train_loss: 0.07066951, train_bce_loss: 0.02705258, train_dice_loss: 0.46322192, train_dice: 0.83804843
valid_loss: 0.04223476, valid_bce_loss: 0.01810232, valid_dice_loss: 0.25942673, valid_dice: 0.87867297
******** Validation loss improved from inf to 0.04223476362744841, saving state ********

Epoch: 2/200 |  time : 09/05/19-19:00:41
=================================================================
train_loss: 0.04344535, train_bce_loss: 0.02102369, train_dice_loss: 0.24524027, train_dice: 0.86589647
valid_loss: 0.04381792, valid_bce_loss: 0.02852964, valid_dice_loss: 0.18141243, valid_dice: 0.88624005

Epoch: 3/200 |  time : 09/05/19-19:26:13
=================================================================
train_loss: 0.03502653, train_bce_loss: 0.02141128, train_dice_loss: 0.15756377, train_dice: 0.89616999
valid_loss: 0.03054586, valid_bce_loss: 0.02039582, valid_dice_loss: 0.12189625, valid_dice: 0.91235476
******** Validation loss improved from 0.04223476362744841 to 0.030545862033646346, saving state ********

Epoch: 4/200 |  time : 09/05/19-19:51:46
=================================================================
train_loss: 0.02991989, train_bce_loss: 0.01897493, train_dice_loss: 0.12842458, train_dice: 0.90801021
valid_loss: 0.02720959, valid_bce_loss: 0.01801166, valid_dice_loss: 0.10999102, valid_dice: 0.91349781
******** Validation loss improved from 0.030545862033646346 to 0.027209591267680824, saving state ********

Epoch: 5/200 |  time : 09/05/19-20:17:17
=================================================================
train_loss: 0.02740804, train_bce_loss: 0.01766763, train_dice_loss: 0.11507179, train_dice: 0.91333200
valid_loss: 0.02861158, valid_bce_loss: 0.02058425, valid_dice_loss: 0.10085752, valid_dice: 0.91526408

Epoch: 6/200 |  time : 09/05/19-20:42:46
=================================================================
train_loss: 0.02683832, train_bce_loss: 0.01738266, train_dice_loss: 0.11193933, train_dice: 0.91465193
valid_loss: 0.02651263, valid_bce_loss: 0.01529202, valid_dice_loss: 0.12749811, valid_dice: 0.91179921
******** Validation loss improved from 0.027209591267680824 to 0.026512627889614497, saving state ********

Epoch: 7/200 |  time : 09/05/19-21:08:18
=================================================================
train_loss: 0.02593132, train_bce_loss: 0.01689152, train_dice_loss: 0.10728957, train_dice: 0.91807127
valid_loss: 0.02852837, valid_bce_loss: 0.02065729, valid_dice_loss: 0.09936805, valid_dice: 0.91787999

Epoch: 8/200 |  time : 09/05/19-21:33:49
=================================================================
train_loss: 0.02528358, train_bce_loss: 0.01644811, train_dice_loss: 0.10480285, train_dice: 0.91876005
valid_loss: 0.02678026, valid_bce_loss: 0.01864931, valid_dice_loss: 0.09995879, valid_dice: 0.91768946

Epoch: 9/200 |  time : 09/05/19-21:59:20
=================================================================
train_loss: 0.02403128, train_bce_loss: 0.01562611, train_dice_loss: 0.09967778, train_dice: 0.92080950
valid_loss: 0.02882210, valid_bce_loss: 0.02060807, valid_dice_loss: 0.10274841, valid_dice: 0.91611989

Epoch: 10/200 |  time : 09/05/19-22:24:50
=================================================================
train_loss: 0.02374932, train_bce_loss: 0.01532083, train_dice_loss: 0.09960575, train_dice: 0.92150262
valid_loss: 0.02533887, valid_bce_loss: 0.01756435, valid_dice_loss: 0.09530955, valid_dice: 0.92300729
******** Validation loss improved from 0.026512627889614497 to 0.025338873207497035, saving state ********

Epoch: 11/200 |  time : 09/05/19-22:50:22
=================================================================
train_loss: 0.02309573, train_bce_loss: 0.01483600, train_dice_loss: 0.09743329, train_dice: 0.92266533
valid_loss: 0.03078131, valid_bce_loss: 0.02375341, valid_dice_loss: 0.09403236, valid_dice: 0.91616810

Epoch: 12/200 |  time : 09/05/19-23:15:52
=================================================================
train_loss: 0.02308994, train_bce_loss: 0.01504836, train_dice_loss: 0.09546408, train_dice: 0.92504108
valid_loss: 0.02712407, valid_bce_loss: 0.02003731, valid_dice_loss: 0.09090490, valid_dice: 0.92177473

Epoch: 13/200 |  time : 09/05/19-23:41:22
=================================================================
train_loss: 0.02287325, train_bce_loss: 0.01474361, train_dice_loss: 0.09603997, train_dice: 0.92482659
valid_loss: 0.02720007, valid_bce_loss: 0.01920117, valid_dice_loss: 0.09919020, valid_dice: 0.92115513

Epoch: 14/200 |  time : 09/06/19-00:06:52
=================================================================
train_loss: 0.02167969, train_bce_loss: 0.01414164, train_dice_loss: 0.08952215, train_dice: 0.92832527
valid_loss: 0.02580656, valid_bce_loss: 0.01832271, valid_dice_loss: 0.09316119, valid_dice: 0.92275588

Epoch: 15/200 |  time : 09/06/19-00:32:23
=================================================================
train_loss: 0.02200853, train_bce_loss: 0.01440523, train_dice_loss: 0.09043821, train_dice: 0.92766637
valid_loss: 0.02408102, valid_bce_loss: 0.01368718, valid_dice_loss: 0.11762564, valid_dice: 0.92466482
******** Validation loss improved from 0.025338873207497035 to 0.024081023274761713, saving state ********

Epoch: 16/200 |  time : 09/06/19-00:57:54
=================================================================
train_loss: 0.02237186, train_bce_loss: 0.01447877, train_dice_loss: 0.09340966, train_dice: 0.92604995
valid_loss: 0.02175969, valid_bce_loss: 0.01426626, valid_dice_loss: 0.08920054, valid_dice: 0.92707067
******** Validation loss improved from 0.024081023274761713 to 0.02175968576649892, saving state ********

Epoch: 17/200 |  time : 09/06/19-01:23:25
=================================================================
train_loss: 0.02404935, train_bce_loss: 0.01561311, train_dice_loss: 0.09997548, train_dice: 0.92314351
valid_loss: 0.02304602, valid_bce_loss: 0.01514001, valid_dice_loss: 0.09420009, valid_dice: 0.92343539

Epoch: 18/200 |  time : 09/06/19-01:48:55
=================================================================
train_loss: 0.02307361, train_bce_loss: 0.01500784, train_dice_loss: 0.09566550, train_dice: 0.92435722
valid_loss: 0.02935453, valid_bce_loss: 0.02131658, valid_dice_loss: 0.10169605, valid_dice: 0.91316318

Epoch: 19/200 |  time : 09/06/19-02:14:24
=================================================================
train_loss: 0.02186573, train_bce_loss: 0.01420853, train_dice_loss: 0.09078046, train_dice: 0.92748331
valid_loss: 0.02453628, valid_bce_loss: 0.01594019, valid_dice_loss: 0.10190112, valid_dice: 0.92012898

Epoch: 20/200 |  time : 09/06/19-02:39:52
=================================================================
train_loss: 0.02129028, train_bce_loss: 0.01383929, train_dice_loss: 0.08834919, train_dice: 0.92879912
valid_loss: 0.02704953, valid_bce_loss: 0.01952314, valid_dice_loss: 0.09478700, valid_dice: 0.92398038

Epoch: 21/200 |  time : 09/06/19-03:05:22
=================================================================
train_loss: 0.02212749, train_bce_loss: 0.01435089, train_dice_loss: 0.09211686, train_dice: 0.92875975
valid_loss: 0.02167053, valid_bce_loss: 0.01477208, valid_dice_loss: 0.08375664, valid_dice: 0.93352522
******** Validation loss improved from 0.02175968576649892 to 0.0216705337509323, saving state ********

Epoch: 22/200 |  time : 09/06/19-03:30:54
=================================================================
train_loss: 0.02067451, train_bce_loss: 0.01343466, train_dice_loss: 0.08583314, train_dice: 0.93076332
valid_loss: 0.02410072, valid_bce_loss: 0.01720316, valid_dice_loss: 0.08617878, valid_dice: 0.92618273

Epoch: 23/200 |  time : 09/06/19-03:56:23
=================================================================
train_loss: 0.02448272, train_bce_loss: 0.01580138, train_dice_loss: 0.10261475, train_dice: 0.92096226
valid_loss: 0.02729710, valid_bce_loss: 0.02068379, valid_dice_loss: 0.08681688, valid_dice: 0.92392426

Epoch: 24/200 |  time : 09/06/19-04:21:52
=================================================================
train_loss: 0.02324622, train_bce_loss: 0.01509257, train_dice_loss: 0.09662906, train_dice: 0.92323056
valid_loss: 0.03483788, valid_bce_loss: 0.02735551, valid_dice_loss: 0.10217916, valid_dice: 0.91715930

Epoch: 25/200 |  time : 09/06/19-04:47:22
=================================================================
train_loss: 0.02308264, train_bce_loss: 0.01491744, train_dice_loss: 0.09656938, train_dice: 0.92480610
valid_loss: 0.04070874, valid_bce_loss: 0.03138599, valid_dice_loss: 0.12461344, valid_dice: 0.90039671

Epoch: 26/200 |  time : 09/06/19-05:12:50
=================================================================
train_loss: 0.02286809, train_bce_loss: 0.01485035, train_dice_loss: 0.09502779, train_dice: 0.92385540
valid_loss: 0.02357330, valid_bce_loss: 0.01660925, valid_dice_loss: 0.08624977, valid_dice: 0.92863635

Epoch: 27/200 |  time : 09/06/19-05:38:19
=================================================================
train_loss: 0.02218522, train_bce_loss: 0.01436247, train_dice_loss: 0.09258994, train_dice: 0.92622752
valid_loss: 0.02156425, valid_bce_loss: 0.01454707, valid_dice_loss: 0.08471888, valid_dice: 0.92986759
******** Validation loss improved from 0.0216705337509323 to 0.021564249609738635, saving state ********

Epoch: 28/200 |  time : 09/06/19-06:03:49
=================================================================
train_loss: 0.02789779, train_bce_loss: 0.01805610, train_dice_loss: 0.11647299, train_dice: 0.91302329
valid_loss: 0.02943495, valid_bce_loss: 0.02074211, valid_dice_loss: 0.10767056, valid_dice: 0.91355054

Epoch: 29/200 |  time : 09/06/19-06:29:20
=================================================================
train_loss: 0.02197750, train_bce_loss: 0.01406089, train_dice_loss: 0.09322700, train_dice: 0.92571769
valid_loss: 0.03106909, valid_bce_loss: 0.02387575, valid_dice_loss: 0.09580921, valid_dice: 0.91440030

Epoch: 30/200 |  time : 09/06/19-06:54:50
=================================================================
train_loss: 0.02379621, train_bce_loss: 0.01529491, train_dice_loss: 0.10030785, train_dice: 0.92137103
valid_loss: 0.03384889, valid_bce_loss: 0.02421029, valid_dice_loss: 0.12059624, valid_dice: 0.90887856

Epoch: 31/200 |  time : 09/06/19-07:20:21
=================================================================
train_loss: 0.02626685, train_bce_loss: 0.01678121, train_dice_loss: 0.11163768, train_dice: 0.91545560
valid_loss: 0.04047414, valid_bce_loss: 0.02888971, valid_dice_loss: 0.14473402, valid_dice: 0.88840026

Epoch: 32/200 |  time : 09/06/19-07:45:49
=================================================================
train_loss: 0.02474072, train_bce_loss: 0.01593789, train_dice_loss: 0.10396617, train_dice: 0.91903658
valid_loss: 0.02404570, valid_bce_loss: 0.01574202, valid_dice_loss: 0.09877890, valid_dice: 0.92153559

Epoch: 33/200 |  time : 09/06/19-08:11:19
=================================================================
train_loss: 0.02215973, train_bce_loss: 0.01444034, train_dice_loss: 0.09163421, train_dice: 0.92578700
valid_loss: 0.02208899, valid_bce_loss: 0.01418665, valid_dice_loss: 0.09321006, valid_dice: 0.92543965
Epoch    32: reducing learning rate of group 0 to 5.0000e-03.

Epoch: 34/200 |  time : 09/06/19-08:36:48
=================================================================
train_loss: 0.01863107, train_bce_loss: 0.01185845, train_dice_loss: 0.07958468, train_dice: 0.93565002
valid_loss: 0.02147174, valid_bce_loss: 0.01488273, valid_dice_loss: 0.08077284, valid_dice: 0.93426969
******** Validation loss improved from 0.021564249609738635 to 0.021471737542466167, saving state ********

Epoch: 35/200 |  time : 09/06/19-09:02:19
=================================================================
train_loss: 0.01806782, train_bce_loss: 0.01166237, train_dice_loss: 0.07571686, train_dice: 0.93707675
valid_loss: 0.02767056, valid_bce_loss: 0.02010394, valid_dice_loss: 0.09577015, valid_dice: 0.91831342

Epoch: 36/200 |  time : 09/06/19-09:27:48
=================================================================
train_loss: 0.01796692, train_bce_loss: 0.01149772, train_dice_loss: 0.07618968, train_dice: 0.93697071
valid_loss: 0.02938356, valid_bce_loss: 0.02336602, valid_dice_loss: 0.08354145, valid_dice: 0.92539848

Epoch: 37/200 |  time : 09/06/19-09:53:17
=================================================================
train_loss: 0.01707146, train_bce_loss: 0.01082831, train_dice_loss: 0.07325975, train_dice: 0.93938899
valid_loss: 0.01885708, valid_bce_loss: 0.01200387, valid_dice_loss: 0.08053600, valid_dice: 0.93480177
******** Validation loss improved from 0.021471737542466167 to 0.01885708170573126, saving state ********

Epoch: 38/200 |  time : 09/06/19-10:18:48
=================================================================
train_loss: 0.01760944, train_bce_loss: 0.01120766, train_dice_loss: 0.07522546, train_dice: 0.93750781
valid_loss: 0.02752974, valid_bce_loss: 0.02071644, valid_dice_loss: 0.08884951, valid_dice: 0.92027257

Epoch: 39/200 |  time : 09/06/19-10:44:17
=================================================================
train_loss: 0.01809878, train_bce_loss: 0.01151205, train_dice_loss: 0.07737933, train_dice: 0.93595336
valid_loss: 0.02259215, valid_bce_loss: 0.01580023, valid_dice_loss: 0.08371940, valid_dice: 0.93117015

Epoch: 40/200 |  time : 09/06/19-11:09:46
=================================================================
train_loss: 0.01703759, train_bce_loss: 0.01091677, train_dice_loss: 0.07212493, train_dice: 0.93979078
valid_loss: 0.02192547, valid_bce_loss: 0.01446560, valid_dice_loss: 0.08906432, valid_dice: 0.92985509

Epoch: 41/200 |  time : 09/06/19-11:35:16
=================================================================
train_loss: 0.01683732, train_bce_loss: 0.01084657, train_dice_loss: 0.07075407, train_dice: 0.94117703
valid_loss: 0.03161257, valid_bce_loss: 0.02505982, valid_dice_loss: 0.09058735, valid_dice: 0.92280714

Epoch: 42/200 |  time : 09/06/19-12:00:45
=================================================================
train_loss: 0.01666738, train_bce_loss: 0.01063205, train_dice_loss: 0.07098540, train_dice: 0.94125398
valid_loss: 0.03008692, valid_bce_loss: 0.02422242, valid_dice_loss: 0.08286745, valid_dice: 0.92533376

Epoch: 43/200 |  time : 09/06/19-12:26:15
=================================================================
train_loss: 0.01699420, train_bce_loss: 0.01076997, train_dice_loss: 0.07301232, train_dice: 0.94048087
valid_loss: 0.02247686, valid_bce_loss: 0.01615776, valid_dice_loss: 0.07934875, valid_dice: 0.93333758
Epoch    42: reducing learning rate of group 0 to 2.5000e-03.

Epoch: 44/200 |  time : 09/06/19-12:51:44
=================================================================
train_loss: 0.01538502, train_bce_loss: 0.00973191, train_dice_loss: 0.06626309, train_dice: 0.94509066
valid_loss: 0.01872840, valid_bce_loss: 0.01251330, valid_dice_loss: 0.07466425, valid_dice: 0.93900159
******** Validation loss improved from 0.01885708170573126 to 0.018728395647627443, saving state ********

Epoch: 45/200 |  time : 09/06/19-13:17:17
=================================================================
train_loss: 0.01466608, train_bce_loss: 0.00928416, train_dice_loss: 0.06310329, train_dice: 0.94844042
valid_loss: 0.01903664, valid_bce_loss: 0.01254286, valid_dice_loss: 0.07748061, valid_dice: 0.93539900

Epoch: 46/200 |  time : 09/06/19-13:42:48
=================================================================
train_loss: 0.01479917, train_bce_loss: 0.00940950, train_dice_loss: 0.06330617, train_dice: 0.94747863
valid_loss: 0.01802243, valid_bce_loss: 0.01188020, valid_dice_loss: 0.07330251, valid_dice: 0.93862174
******** Validation loss improved from 0.018728395647627443 to 0.018022431242709556, saving state ********

Epoch: 47/200 |  time : 09/06/19-14:08:18
=================================================================
train_loss: 0.01477792, train_bce_loss: 0.00942870, train_dice_loss: 0.06292092, train_dice: 0.94796693
valid_loss: 0.02678858, valid_bce_loss: 0.02132428, valid_dice_loss: 0.07596729, valid_dice: 0.93310106

Epoch: 48/200 |  time : 09/06/19-14:33:47
=================================================================
train_loss: 0.01402652, train_bce_loss: 0.00890031, train_dice_loss: 0.06016248, train_dice: 0.94993580
valid_loss: 0.01817901, valid_bce_loss: 0.01288974, valid_dice_loss: 0.06578243, valid_dice: 0.94369361

Epoch: 49/200 |  time : 09/06/19-14:59:18
=================================================================
train_loss: 0.01412541, train_bce_loss: 0.00913755, train_dice_loss: 0.05901615, train_dice: 0.95129078
valid_loss: 0.02485892, valid_bce_loss: 0.01928599, valid_dice_loss: 0.07501529, valid_dice: 0.93415564

Epoch: 50/200 |  time : 09/06/19-15:24:48
=================================================================
train_loss: 0.01382155, train_bce_loss: 0.00882177, train_dice_loss: 0.05881959, train_dice: 0.95116779
valid_loss: 0.02234609, valid_bce_loss: 0.01651368, valid_dice_loss: 0.07483773, valid_dice: 0.93412110

Epoch: 51/200 |  time : 09/06/19-15:50:17
=================================================================
train_loss: 0.01371350, train_bce_loss: 0.00877982, train_dice_loss: 0.05811655, train_dice: 0.95166335
valid_loss: 0.02903474, valid_bce_loss: 0.02385210, valid_dice_loss: 0.07567841, valid_dice: 0.93213444

Epoch: 52/200 |  time : 09/06/19-16:15:46
=================================================================
train_loss: 0.01370074, train_bce_loss: 0.00861840, train_dice_loss: 0.05944178, train_dice: 0.95051287
valid_loss: 0.02442427, valid_bce_loss: 0.01901518, valid_dice_loss: 0.07310608, valid_dice: 0.93432017
Epoch    51: reducing learning rate of group 0 to 1.2500e-03.

Epoch: 53/200 |  time : 09/06/19-16:41:16
=================================================================
train_loss: 0.01324875, train_bce_loss: 0.00850256, train_dice_loss: 0.05596453, train_dice: 0.95355828
valid_loss: 0.02203578, valid_bce_loss: 0.01658338, valid_dice_loss: 0.07110733, valid_dice: 0.93680289

Epoch: 54/200 |  time : 09/06/19-17:06:45
=================================================================
